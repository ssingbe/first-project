{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ì í˜ì´ì§€ í¬ë¡¤ë§ ë°©ë²•ìœ¼ë¡œ ë¶ˆê°€ëŠ¥ëŠ¥\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://exhibitors.ces.tech/8_0/#/searchtype/category/search/999999999/show/cat-category%7C240\")\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "type(soup.select_one(\"#exhibitor-results > div.results-list-view.toggle-list-view > table > tbody > tr:nth-child(4) > td.is-hidden_small.card-Desc.f6\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium==4.17.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì…€ë ˆë‹ˆì›€ìœ¼ë¡œ í˜ì´ì§€ë¥¼ ì—´ê³  ì•Œë§¹ì´ë¥¼ ë°›ì•„ì˜¨ ë‹¤ìŒ ì¶”ì¶œí•˜ê¸°\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#í¬ë¡¬ ë“œë¼ì´ë²„ ìƒì„±\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# í˜ì´ì§€ ì´ë™\n",
    "driver.get(\"https://exhibitors.ces.tech/8_0/#/searchtype/category/search/999999999/show/cat-category%7C240\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ë“œë¼ì´ë²„ì˜ HTML ê°€ì ¸ì˜¤ê¸°\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select_one(\".card-Desc f5 lh-copy ma0 muted\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë” ì´ìƒ ë¡œë“œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NDFrame.to_excel() got an unexpected keyword argument 'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scraped_data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# ë°ì´í„° ì»¬ëŸ¼ ì´ë¦„ ìˆ˜ì • ê°€ëŠ¥\u001b[39;00m\n\u001b[0;32m     44\u001b[0m excel_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscraped_data.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# ì €ì¥í•  íŒŒì¼ ì´ë¦„\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124më°ì´í„°ê°€ \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexcel_file_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124më¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\python_Study\\python_crawling\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: NDFrame.to_excel() got an unexpected keyword argument 'encoding'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 1. WebDriver ì„¤ì •\n",
    "driver = webdriver.Chrome()  # chromedriverì˜ ê²½ë¡œë¥¼ ì§€ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "url = \"https://exhibitors.ces.tech/8_0/#/searchtype/category/search/999999999/show/cat-category%7C240\"  # í¬ë¡¤ë§í•  ëŒ€ìƒ URLë¡œ êµì²´í•˜ì„¸ìš”\n",
    "driver.get(url)\n",
    "\n",
    "# 2. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "time.sleep(3)\n",
    "\n",
    "# 3. ìŠ¤í¬ë¡¤ ë° ë” ë§ì€ ì½˜í…ì¸  ë¡œë“œ\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")  # ì´ˆê¸° ìŠ¤í¬ë¡¤ ë†’ì´ ê°€ì ¸ì˜¤ê¸°\n",
    "scraped_data = []  # ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "while True:\n",
    "    # í˜ì´ì§€ì˜ ë§¨ ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ì½˜í…ì¸ ê°€ ë¡œë“œë˜ë„ë¡ ëŒ€ê¸°\n",
    "    time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ì‹œê°„ì— ë”°ë¼ ëŒ€ê¸° ì‹œê°„ì„ ì¡°ì •í•˜ì„¸ìš”\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ìŠ¤í¬ë¡¤ ë†’ì´ ê°€ì ¸ì˜¤ê¸°\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # ìŠ¤í¬ë¡¤ ë†’ì´ì— ë³€í™”ê°€ ì—†ìœ¼ë©´ ë°˜ë³µ ì¢…ë£Œ\n",
    "    if new_height == last_height:\n",
    "        print(\"ë” ì´ìƒ ë¡œë“œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# 4. ìŠ¤í¬ë¡¤ í›„ ë°ì´í„° ì¶”ì¶œ\n",
    "data_elements = driver.find_elements(By.CLASS_NAME, 'card-Title break-word f2 mb1 mt0')  # ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”\n",
    "for element in data_elements:\n",
    "    scraped_data.append(element.text)  # í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "\n",
    "# 5. ë¸Œë¼ìš°ì € ë‹«ê¸°\n",
    "driver.quit()\n",
    "\n",
    "# 6. ë°ì´í„° ì €ì¥: Pandas DataFrameìœ¼ë¡œ ë³€í™˜ ë° Excel ì €ì¥\n",
    "df = pd.DataFrame(scraped_data, columns=[\"Content\"])  # ë°ì´í„° ì»¬ëŸ¼ ì´ë¦„ ìˆ˜ì • ê°€ëŠ¥\n",
    "excel_file_name = \"scraped_data.xlsx\"  # ì €ì¥í•  íŒŒì¼ ì´ë¦„\n",
    "df.to_excel(excel_file_name, index=False, encoding=\"utf-8\")\n",
    "print(f\"ë°ì´í„°ê°€ '{excel_file_name}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë” ì´ìƒ ë¡œë“œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "ë°ì´í„°ê°€ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: scraped_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd  # Import pandas for saving data to Excel\n",
    "\n",
    "# 1. WebDriver ì„¤ì •\n",
    "driver = webdriver.Chrome()  # chromedriver ê²½ë¡œë¥¼ ì§€ì •í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "url = \"https://exhibitors.ces.tech/8_0/#/searchtype/category/search/999999999/show/cat-category%7C240\"  # CES 2025 URL\n",
    "driver.get(url)\n",
    "\n",
    "# 2. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "time.sleep(15)\n",
    "\n",
    "# 3. ìŠ¤í¬ë¡¤ ë° ë” ë§ì€ ì½˜í…ì¸  ë¡œë“œ\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")  # ì´ˆê¸° ìŠ¤í¬ë¡¤ ë†’ì´\n",
    "scraped_data = []  # ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "while True:\n",
    "    # í˜ì´ì§€ì˜ ë§¨ ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ì½˜í…ì¸ ê°€ ë¡œë“œë˜ë„ë¡ ëŒ€ê¸°\n",
    "    time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ì‹œê°„ì— ë”°ë¼ ëŒ€ê¸° ì‹œê°„ ì¡°ì •\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ìŠ¤í¬ë¡¤ ë†’ì´ í™•ì¸\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # ìŠ¤í¬ë¡¤ ë†’ì´ì— ë³€í™”ê°€ ì—†ìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ\n",
    "    if new_height == last_height:\n",
    "        print(\"ë” ì´ìƒ ë¡œë“œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# 4. ë°ì´í„° ì¶”ì¶œ: p íƒœê·¸ í´ë˜ìŠ¤ê°€ 'card-Desc f5 lh-copy ma0 muted'ì¸ ìš”ì†Œ ë‚´ì˜ a íƒœê·¸ ì°¾ê¸°\n",
    "p_elements = driver.find_elements(By.CLASS_NAME, 'card-Desc f5 lh-copy ma0 muted')  # p ìš”ì†Œë¥¼ ì°¾ìŒ\n",
    "for p in p_elements:\n",
    "    # p ë‚´ì˜ a íƒœê·¸ ì°¾ê¸°\n",
    "    a_tag = p.find_element(By.TAG_NAME, 'a')  # a íƒœê·¸ ì°¾ê¸°\n",
    "    \n",
    "    # a íƒœê·¸ ë‚´ì˜ href ì†ì„±ê°’ ì¶”ì¶œ\n",
    "    href_value = a_tag.get_attribute('href')\n",
    "    \n",
    "    # ì°¾ì€ href ê°’ì— ëŒ€í•œ ì¶”ê°€ì ì¸ í´ë˜ìŠ¤ê°€ 'bb-0'ì¸ ìš”ì†Œ ë‚´ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ\n",
    "    bb0_element = a_tag.find_element(By.CLASS_NAME, 'bb-0')  # 'bb-0' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œ ì°¾ê¸°\n",
    "    if bb0_element:\n",
    "        scraped_data.append({\"Link\": href_value, \"BB0 Content\": bb0_element.text})  # ë§í¬ì™€ ë‚´ìš© ì €ì¥\n",
    "\n",
    "# 5. ë¸Œë¼ìš°ì € ë‹«ê¸°\n",
    "driver.quit()\n",
    "\n",
    "# 6. ë°ì´í„° ì €ì¥: Pandas DataFrameìœ¼ë¡œ ë³€í™˜ ë° Excel ì €ì¥\n",
    "df = pd.DataFrame(scraped_data)  # DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "output_file = \"scraped_data.xlsx\"  # ì €ì¥í•  íŒŒì¼ ì´ë¦„\n",
    "\n",
    "# Excel íŒŒì¼ë¡œ ì €ì¥ (encoding ì œê±°)\n",
    "df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "print(f\"ë°ì´í„°ê°€ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 14:30:46,530 - INFO - ====== WebDriver manager ======\n",
      "2025-01-03 14:30:48,153 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-01-03 14:30:48,172 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-01-03 14:30:49,203 - INFO - Driver [C:\\Users\\CTE22-213\\.wdm\\drivers\\chromedriver\\win64\\131.0.6778.204\\chromedriver-win32/chromedriver.exe] found in cache\n",
      "2025-01-03 14:30:53,631 - INFO - ë©”ì¸ í˜ì´ì§€ ì ‘ì†: https://exhibitors.ces.tech/8_0/#/searchtype/category/search/999999999/show/cat-category%7C215\n",
      "2025-01-03 14:31:29,110 - ERROR - ì „ì‹œì—…ì²´ ì¹´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "2025-01-03 14:31:29,110 - ERROR - ì „ì‹œì—…ì²´ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('scraper.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class CESExhibitorScraper:\n",
    "    def __init__(self):\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument(\"--headless\")\n",
    "        self.chrome_options.add_argument(\"--disable-gpu\")\n",
    "        self.chrome_options.add_argument(\"--no-sandbox\")\n",
    "        self.chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        self.chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        \n",
    "        # User-Agent ì¶”ê°€\n",
    "        self.chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "        \n",
    "        self.service = Service(ChromeDriverManager().install())\n",
    "        self.driver = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.driver = webdriver.Chrome(service=self.service, options=self.chrome_options)\n",
    "        self.wait = WebDriverWait(self.driver, 30)  # ëŒ€ê¸° ì‹œê°„ì„ 30ì´ˆë¡œ ì¦ê°€\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            \n",
    "    def wait_for_page_load(self):\n",
    "        \"\"\"í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°\"\"\"\n",
    "        try:\n",
    "            self.wait.until(lambda driver: driver.execute_script('return document.readyState') == 'complete')\n",
    "            time.sleep(5)  # ì¶”ê°€ ëŒ€ê¸° ì‹œê°„\n",
    "        except TimeoutException:\n",
    "            logging.warning(\"í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼\")\n",
    "            \n",
    "    def scroll_page(self, timeout: int = 60) -> None:  # íƒ€ì„ì•„ì›ƒ ì¦ê°€\n",
    "        \"\"\"í˜ì´ì§€ë¥¼ ì²œì²œíˆ ìŠ¤í¬ë¡¤í•˜ë©° ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ\"\"\"\n",
    "        start_time = time.time()\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        while True:\n",
    "            # ì²œì²œíˆ ìŠ¤í¬ë¡¤\n",
    "            for i in range(10):\n",
    "                self.driver.execute_script(f\"window.scrollTo(0, {last_height * (i/10)});\")\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            time.sleep(3)  # ë¡œë”© ëŒ€ê¸° ì‹œê°„ ì¦ê°€\n",
    "            \n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height or time.time() - start_time > timeout:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            \n",
    "    def get_exhibitor_links(self, url: str) -> List[str]:\n",
    "        \"\"\"ë©”ì¸ í˜ì´ì§€ì—ì„œ ëª¨ë“  ì „ì‹œì—…ì²´ ë§í¬ ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "            logging.info(\"ë©”ì¸ í˜ì´ì§€ ì ‘ì†: %s\", url)\n",
    "            \n",
    "            # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°\n",
    "            self.wait_for_page_load()\n",
    "            \n",
    "            # Accept ë²„íŠ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í´ë¦­\n",
    "            try:\n",
    "                accept_button = self.driver.find_element(By.CSS_SELECTOR, \"button[aria-label='Accept']\")\n",
    "                accept_button.click()\n",
    "                time.sleep(2)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°\n",
    "            try:\n",
    "                self.wait.until(EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, \"h3 card-Title break-word dib f5 ma0 a\")\n",
    "                ))\n",
    "            except TimeoutException:\n",
    "                logging.error(\"ì „ì‹œì—…ì²´ ì¹´ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return []\n",
    "            \n",
    "            self.scroll_page()\n",
    "            \n",
    "            # ì—¬ëŸ¬ ë²ˆ ì‹œë„í•˜ì—¬ ë§í¬ ìˆ˜ì§‘\n",
    "            max_attempts = 3\n",
    "            for attempt in range(max_attempts):\n",
    "                elements = self.driver.find_elements(\n",
    "                    By.CSS_SELECTOR, \n",
    "                    \"h3 card-Title break-word dib f5 ma0 a\"\n",
    "                )\n",
    "                links = [element.get_attribute(\"href\") for element in elements]\n",
    "                \n",
    "                if links:\n",
    "                    logging.info(\"ì „ì‹œì—…ì²´ ë§í¬ %dê°œ ë°œê²¬ (ì‹œë„ %d)\", len(links), attempt + 1)\n",
    "                    return links\n",
    "                    \n",
    "                if attempt < max_attempts - 1:\n",
    "                    logging.warning(\"ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¬ì‹œë„ ì¤‘... (%d/%d)\", attempt + 1, max_attempts)\n",
    "                    time.sleep(5)\n",
    "                    self.scroll_page()\n",
    "            \n",
    "            logging.error(\"ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼\")\n",
    "            return []\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(\"ì „ì‹œì—…ì²´ ë§í¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: %s\", str(e))\n",
    "            return []\n",
    "            \n",
    "    def get_exhibitor_data(self, links: List[str]) -> List[Dict]:\n",
    "        \"\"\"ê° ì „ì‹œì—…ì²´ í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        for i, link in enumerate(links, 1):\n",
    "            try:\n",
    "                self.driver.get(link)\n",
    "                self.wait_for_page_load()\n",
    "                logging.info(\"[%d/%d] ì²˜ë¦¬ ì¤‘: %s\", i, len(links), link)\n",
    "                \n",
    "                # ì£¼ì†Œ ìš”ì†Œ ëŒ€ê¸°\n",
    "                try:\n",
    "                    address_element = self.wait.until(EC.presence_of_element_located(\n",
    "                        (By.CSS_SELECTOR, \"showcase-address tc\")\n",
    "                    ))\n",
    "                except TimeoutException:\n",
    "                    logging.warning(\"ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: %s\", link)\n",
    "                    continue\n",
    "                \n",
    "                # ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘\n",
    "                company_name = self.safe_get_text(\".company-name\")\n",
    "                booth_number = self.safe_get_text(\".booth-number\")\n",
    "                description = self.safe_get_text(\".company-description\")\n",
    "                \n",
    "                data.append({\n",
    "                    \"Link\": link,\n",
    "                    \"Company\": company_name,\n",
    "                    \"Address\": address_element.text,\n",
    "                    \"Booth\": booth_number,\n",
    "                    \"Description\": description\n",
    "                })\n",
    "                \n",
    "                time.sleep(2)  # ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ ì¦ê°€\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(\"ë§í¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ %s: %s\", link, str(e))\n",
    "                \n",
    "        return data\n",
    "        \n",
    "    def safe_get_text(self, selector: str) -> str:\n",
    "        \"\"\"ìš”ì†Œê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        try:\n",
    "            element = self.driver.find_element(By.CSS_SELECTOR, selector)\n",
    "            return element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            return \"\"\n",
    "            \n",
    "    def save_to_excel(self, data: List[Dict], filename: str) -> None:\n",
    "        \"\"\"ë°ì´í„°ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        try:\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_excel(filename, index=False, engine=\"openpyxl\")\n",
    "            logging.info(\"ë°ì´í„°ê°€ %s íŒŒì¼ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë¨\", filename)\n",
    "        except Exception as e:\n",
    "            logging.error(\"Excel ì €ì¥ ì¤‘ ì˜¤ë¥˜: %s\", str(e))\n",
    "\n",
    "def main():\n",
    "    url = \"https://exhibitors.ces.tech/8_0/#/searchtype/category/search/999999999/show/cat-category%7C215\"\n",
    "    output_file = \"ces_exhibitors_data.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        with CESExhibitorScraper() as scraper:\n",
    "            links = scraper.get_exhibitor_links(url)\n",
    "            if not links:\n",
    "                logging.error(\"ì „ì‹œì—…ì²´ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                return\n",
    "                \n",
    "            data = scraper.get_exhibitor_data(links)\n",
    "            if data:\n",
    "                scraper.save_to_excel(data, output_file)\n",
    "            else:\n",
    "                logging.error(\"ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        logging.error(\"ì¹˜ëª…ì  ì˜¤ë¥˜: %s\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!\n",
      "ğŸ“„ ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ ì™„ë£Œ!\n",
      "ğŸš¨ ë°ì´í„° íƒìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: Message: \n",
      "\n",
      "ğŸ’¾ ë°ì´í„°ê°€ 'CES_Exhibitors_Summary_with_button.xlsx'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 1. WebDriver ì„¤ì •\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "url = \"https://exhibitors.ces.tech/8_0/explore/exhibitor-gallery.cfm?featured=false\"\n",
    "driver.get(url)\n",
    "\n",
    "# 2. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "time.sleep(10)\n",
    "\n",
    "# 3. 'is-selected toggle-grid btn-tertiary' ë²„íŠ¼ í´ë¦­\n",
    "try:\n",
    "    button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"span.is-selected.toggle-grid.btn-tertiary\"))\n",
    "    )\n",
    "    button.click()\n",
    "    print(\"âœ… ë²„íŠ¼ í´ë¦­ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# 4. í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "time.sleep(10)\n",
    "\n",
    "# 5. í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(10)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°\n",
    "\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        print(\"ğŸ“„ ëª¨ë“  ì½˜í…ì¸  ë¡œë“œ ì™„ë£Œ!\")\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "# 6. ë°ì´í„° ì¶”ì¶œ\n",
    "scraped_data = []\n",
    "\n",
    "try:\n",
    "    # ì „ì‹œëª…(Exhibitor) íƒìƒ‰\n",
    "    exhibitors = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'h3.card-Title.break-word.dib.f5.ma0'))\n",
    "    )\n",
    "    # ì„¤ëª…(Summary) íƒìƒ‰\n",
    "    descriptions = driver.find_elements(By.CSS_SELECTOR, 'td.is-hidden_small.card-Desc.f6 span')\n",
    "\n",
    "    # ì „ì‹œëª… & ì„¤ëª… ë‚´ìš© ë§¤ì¹­\n",
    "    for exhibitor, description in zip(exhibitors, descriptions):\n",
    "        exhibitor_name = exhibitor.text.strip() if exhibitor.text else \"N/A\"\n",
    "        summary_text = description.text.strip() if description.text else \"N/A\"\n",
    "\n",
    "        scraped_data.append({\n",
    "            \"Exhibitor\": exhibitor_name,\n",
    "            \"Summary\": summary_text\n",
    "        })\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ ë°ì´í„° íƒìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# 7. ë¸Œë¼ìš°ì € ì¢…ë£Œ\n",
    "driver.quit()\n",
    "\n",
    "# 8. DataFrame ìƒì„± ë° Excel ì €ì¥\n",
    "df = pd.DataFrame(scraped_data)\n",
    "output_file = \"CES_Exhibitors_Summary_with_button.xlsx\"\n",
    "df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"ğŸ’¾ ë°ì´í„°ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
