WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00.429 --> 00:03.012
(upbeat music)

00:10.320 --> 00:11.683
<v ->Awesome.</v>

00:11.683 --> 00:12.900
So nice to be here with you all.

00:12.900 --> 00:14.610
I think it's good.

00:14.610 --> 00:16.980
We didn't level before, so they're leveling.

00:16.980 --> 00:18.960
It's all good. I give them a couple seconds of me,

00:18.960 --> 00:20.580
talking about random things.

00:20.580 --> 00:21.860
I don't know

00:21.860 --> 00:23.940
if you all remember these beautiful glasses.

00:23.940 --> 00:25.080
I've worn them on

00:25.080 --> 00:27.720
I think six CES stages

00:27.720 --> 00:29.610
since they launched years ago,

00:29.610 --> 00:30.443
the Meta frame.

00:30.443 --> 00:32.670
So I always like to just tell people at home

00:32.670 --> 00:34.530
what this actually looks like,

00:34.530 --> 00:36.555
like being here and standing in front of you.

00:36.555 --> 00:37.680
So thank you for taking time

00:37.680 --> 00:39.960
out of your crazy schedule at CES

00:39.960 --> 00:41.730
to join us today at the AI House.

00:41.730 --> 00:45.360
I have an amazing panel of incredible people

00:45.360 --> 00:48.570
from different parts of industry

00:48.570 --> 00:49.890
as well as practice.

00:49.890 --> 00:51.720
We've got a little policy professionals,

00:51.720 --> 00:54.360
so it's going to be a very fun, wild ride

00:54.360 --> 00:56.040
in the world of really,

00:56.040 --> 00:57.810
what does the workforce look like

00:57.810 --> 00:58.980
as AI starts to,

00:58.980 --> 01:00.660
I don't know, take over everything.

01:00.660 --> 01:02.910
So I wanna invite my panelists to come on up.

01:03.780 --> 01:04.613
I'm gonna see

01:04.613 --> 01:06.480
where I wanna put them seat-wise.

01:06.480 --> 01:07.650
Come on, let's go.

01:07.650 --> 01:08.520
I'm gonna invite-

01:08.520 --> 01:09.728
Okay.

01:09.728 --> 01:11.280
I'll say Lindsey will come up first

01:11.280 --> 01:15.300
and Lindsey is one of the best storytellers.

01:15.300 --> 01:17.556
Yes, give her a round of applause.

01:17.556 --> 01:18.389
(audience clapping)

01:18.389 --> 01:19.230
One of the best storytellers.

01:19.230 --> 01:22.500
She's anchored many of news broadcasts.

01:22.500 --> 01:23.430
She actually hosted me.

01:23.430 --> 01:24.263
Come on down.

01:24.263 --> 01:25.380
We'll have you sit right there.

01:25.380 --> 01:26.580
Alex, I'm gonna have you sit

01:26.580 --> 01:28.380
where my baby tiger is.

01:28.380 --> 01:30.090
Amazing.

01:30.090 --> 01:31.281
All right.

01:31.281 --> 01:33.307
And then the gentleman can just pick a seat.

01:33.307 --> 01:35.190
(audience laughing)

01:35.190 --> 01:36.030
I hope that doesn't say

01:36.030 --> 01:38.139
a lot about me right there.

01:38.139 --> 01:38.972
(Noelle chuckles)

01:38.972 --> 01:39.805
Yeah, perfect.

01:39.805 --> 01:40.638
Awesome.

01:40.638 --> 01:42.304
All right. Then I'm gonna sit over here.

01:42.304 --> 01:44.130
Cool. I was just gonna take whatever seat was available.

01:44.130 --> 01:47.280
So obviously, we have a lot of people here today

01:47.280 --> 01:48.750
to share with you some perspectives.

01:48.750 --> 01:49.890
I wanna start first

01:49.890 --> 01:52.497
by giving people an opportunity.

01:52.497 --> 01:55.200
My eyeglasses are talking to me.

01:55.200 --> 01:56.853
No, not right now.

01:58.200 --> 02:00.930
The most important thing about the topic

02:00.930 --> 02:02.610
that we're gonna share with you today

02:02.610 --> 02:05.010
is that it impacts every single one of us

02:05.010 --> 02:08.220
and that we all have different lived experiences

02:08.220 --> 02:09.053
and my hope is that,

02:09.053 --> 02:10.320
we'll be able to bring

02:10.320 --> 02:11.940
some of those lived experiences to you

02:11.940 --> 02:14.160
and how we've managed the world

02:14.160 --> 02:16.038
of work and AI

02:16.038 --> 02:18.330
throughout the last couple of years,

02:18.330 --> 02:19.620
some of us much longer.

02:19.620 --> 02:20.580
I'm Noelle Russell

02:20.580 --> 02:23.580
and my journey into the world of AI

02:23.580 --> 02:25.710
started actually at CES.

02:25.710 --> 02:28.830
10 years ago, I helped launch Amazon Alexa.

02:28.830 --> 02:30.330
I was employee 10 on that product.

02:30.330 --> 02:32.130
I built over a hundred apps for Alexa

02:32.130 --> 02:33.330
in its first year,

02:33.330 --> 02:36.630
owned 10% of the applications that were deployed,

02:36.630 --> 02:38.130
got millions of users

02:38.130 --> 02:40.230
and didn't know what the heck I was doing.

02:40.230 --> 02:42.330
And realized that productizing AI

02:42.330 --> 02:44.160
was very much that journey

02:44.160 --> 02:46.083
of getting a good idea,

02:46.083 --> 02:48.690
knowing how to clearly articulate it,

02:48.690 --> 02:49.980
and then get it out into the world.

02:49.980 --> 02:52.230
And so I've productized models at Microsoft,

02:52.230 --> 02:53.793
at IBM, at Red Hat.

02:54.840 --> 02:56.640
I'm a big practitioner,

02:56.640 --> 02:58.410
but what I love most really,

02:58.410 --> 03:01.890
is helping people who didn't really see an opportunity,

03:01.890 --> 03:03.960
didn't see themselves in the world of AI,

03:03.960 --> 03:05.640
start to see themselves that way.

03:05.640 --> 03:07.770
So I have a community which actually,

03:07.770 --> 03:09.372
I think a couple of us are in,

03:09.372 --> 03:10.980
called the I Love-

03:10.980 --> 03:13.170
I know, I have community members in the house.

03:13.170 --> 03:14.460
The I love AI community.

03:14.460 --> 03:15.293
It's a free community

03:15.293 --> 03:17.940
where we just teach literally anyone

03:17.940 --> 03:18.960
the art of AI.

03:18.960 --> 03:21.360
And I do think that that is a core principle

03:21.360 --> 03:22.830
of the workforce topics

03:22.830 --> 03:23.670
we're gonna talk about.

03:23.670 --> 03:24.630
So as we get started,

03:24.630 --> 03:27.300
I wanna give everyone a chance to introduce yourself,

03:27.300 --> 03:29.040
but then also talk a little bit

03:29.040 --> 03:31.980
about how the workforce,

03:31.980 --> 03:33.570
like the concept of the workforce

03:33.570 --> 03:34.403
has changed for you

03:34.403 --> 03:36.270
over the last two years.

03:36.270 --> 03:37.680
And it's totally fine

03:37.680 --> 03:38.760
if it hasn't changed at all,

03:38.760 --> 03:40.765
though I don't think that will be the case.

03:40.765 --> 03:42.180
But I would like to understand

03:42.180 --> 03:43.140
a little bit about your background

03:43.140 --> 03:45.540
and then give us a little idea about

03:45.540 --> 03:47.790
what you think about the workforce right now.

03:47.790 --> 03:48.690
So I'll start with you, Lindsey,

03:48.690 --> 03:50.400
and we'll walk down the lane.

03:50.400 --> 03:51.233
<v ->Sure.</v>

03:51.233 --> 03:52.066
Thank you so much, Noelle.

03:52.066 --> 03:53.250
Thank you for having me.

03:53.250 --> 03:54.510
My name's Lindsey Mastis

03:54.510 --> 03:56.700
and I'm an AI and tech news anchor.

03:56.700 --> 03:58.800
I've been covering AI and tech

03:58.800 --> 04:00.840
for about the past two years.

04:00.840 --> 04:02.580
And up until Friday,

04:02.580 --> 04:04.770
I was in TV broadcast news

04:04.770 --> 04:06.570
and now I've gone independent

04:06.570 --> 04:07.620
so that I can focus on

04:07.620 --> 04:08.850
this pretty much full time.

04:08.850 --> 04:10.440
So it's changed for me.

04:10.440 --> 04:12.630
I've also seen the landscape

04:12.630 --> 04:14.940
within the newsroom change a bit.

04:14.940 --> 04:17.580
It's a little bit slower moving right now

04:17.580 --> 04:19.290
because when it comes to journalists,

04:19.290 --> 04:21.390
we wanna make sure everything's accurate.

04:21.390 --> 04:23.520
So that's a little bit of a holdup.

04:23.520 --> 04:25.380
But I also have reported

04:25.380 --> 04:26.310
on AI and tech,

04:26.310 --> 04:28.770
especially when it comes to the workforce

04:28.770 --> 04:31.590
and a lot of parents that are concerned about

04:31.590 --> 04:34.230
what should their children be learning

04:34.230 --> 04:35.650
when it comes to

04:36.600 --> 04:38.610
what they're gonna be doing in the future.

04:38.610 --> 04:40.080
And then also talking to people

04:40.080 --> 04:41.250
about having to pivot.

04:41.250 --> 04:43.950
So, it's a really a broad spectrum right now,

04:43.950 --> 04:46.860
but yeah, this is really impacting all areas

04:46.860 --> 04:48.270
and it's an exciting time.

04:48.270 --> 04:49.103
<v ->Absolutely.</v>

04:49.103 --> 04:50.970
Thank you very much for that.

04:50.970 --> 04:51.803
All right.

04:51.803 --> 04:53.070
Let's keep going.

04:53.070 --> 04:53.903
<v ->Hi.</v>

04:53.903 --> 04:54.990
Thank you very much for having me.

04:54.990 --> 04:56.460
Brian Scarpelli is my name.

04:56.460 --> 05:00.150
I'm with a trade association based in Washington, DC

05:00.150 --> 05:02.010
called ACT, The App Association.

05:02.010 --> 05:04.710
It's a not-for-profit industry advocate

05:04.710 --> 05:07.680
for the small business software developer

05:07.680 --> 05:09.123
segment of the industry.

05:10.170 --> 05:12.570
And I'm a lawyer for them.

05:12.570 --> 05:13.620
So I thought actually,

05:13.620 --> 05:16.110
I could touch on two kind of different angles.

05:16.110 --> 05:21.110
One, the impact on the developer community,

05:22.200 --> 05:25.200
I think, it's very much seen

05:25.200 --> 05:29.160
as a vital augmentative tool

05:29.160 --> 05:32.980
for code generation and finding bugs

05:33.870 --> 05:36.633
and other quality checks and assurances,

05:38.550 --> 05:39.711
for our community,

05:39.711 --> 05:44.190
these are some micro companies

05:44.190 --> 05:45.570
that have been developing

05:45.570 --> 05:48.870
and using AI for years now.

05:48.870 --> 05:51.843
And they're really leaning in, embracing it.

05:53.310 --> 05:55.353
So there's a lot of positive.

05:56.550 --> 05:59.670
I think quite positive from that perspective.

05:59.670 --> 06:00.720
I mentioned that I'm a lawyer

06:00.720 --> 06:01.560
just because I thought

06:01.560 --> 06:02.710
it would be interesting

06:04.881 --> 06:05.714
to talk about that

06:05.714 --> 06:06.547
just for a moment.

06:06.547 --> 06:08.673
Like how is that impacting the legal profession?

06:10.110 --> 06:13.600
And AI tools are already

06:16.020 --> 06:19.533
pretty critical in just document review, summarizing,

06:19.533 --> 06:20.760
some kind of,

06:20.760 --> 06:22.830
if you wanna call them pedestrian uses,

06:22.830 --> 06:25.443
maybe transcription and things like that.

06:26.940 --> 06:29.520
But there's some really interesting or infamous cases

06:29.520 --> 06:32.013
that people might be aware of lawyers,

06:34.320 --> 06:35.520
submitting briefs to courts

06:35.520 --> 06:38.040
with hallucinated sites and cases,

06:38.040 --> 06:38.873
and things like that,

06:38.873 --> 06:40.221
and them getting into trouble.

06:40.221 --> 06:41.054
<v ->Yeah.</v>

06:41.054 --> 06:42.720
<v ->Yeah. These are themes that I think</v>

06:42.720 --> 06:43.553
we'll probably touch on later.

06:43.553 --> 06:44.730
I just thought I'd mention that too, but-

06:44.730 --> 06:46.075
<v ->Yeah.</v>

06:46.075 --> 06:46.908
Amazing.

06:46.908 --> 06:48.574
Thank you. So we've got, like the scene is being set.

06:48.574 --> 06:51.420
We've got a content creator, a storyteller,

06:51.420 --> 06:54.120
a news professional media represented.

06:54.120 --> 06:57.210
We've now got legal and policy represented.

06:57.210 --> 06:59.820
So I think you'll find the diversity

06:59.820 --> 07:02.850
of experience very, very interesting.

07:02.850 --> 07:05.100
So Bob, I'd like you to go next,

07:05.100 --> 07:05.933
if you don't mind.

07:05.933 --> 07:06.961
<v ->Sure.</v>

07:06.961 --> 07:08.130
Hi, my name is Bob Briski.

07:08.130 --> 07:09.870
I work for a company called DEPT Agency.

07:09.870 --> 07:12.990
We're half creative brand and media agency.

07:12.990 --> 07:14.727
And then the other half is a technical data

07:14.727 --> 07:17.610
and AI portion of the company.

07:17.610 --> 07:20.310
And I work on the data and AI portion

07:20.310 --> 07:22.920
and my team uses data

07:22.920 --> 07:24.990
and a lot of the new generative AI capabilities

07:24.990 --> 07:28.710
to build tools for the creative brand and media side.

07:28.710 --> 07:31.770
And so, we have a couple AI accelerator tools

07:31.770 --> 07:33.690
that help out our global workforce.

07:33.690 --> 07:35.760
And it's been really interesting,

07:35.760 --> 07:36.840
I think what we were talking about

07:36.840 --> 07:39.446
over the last couple of years to see

07:39.446 --> 07:42.180
how the actual use and experience

07:42.180 --> 07:44.482
with these tools changes

07:44.482 --> 07:48.330
the more creative part of our agencies,

07:48.330 --> 07:50.250
view of those tools from fear-based,

07:50.250 --> 07:51.150
I think at the beginning

07:51.150 --> 07:53.730
to real embrace and feedback

07:53.730 --> 07:56.850
and like hunger for more of these types of tools

07:56.850 --> 07:58.920
to make their daily lives

07:58.920 --> 07:59.753
just a little bit easier,

07:59.753 --> 08:00.586
a little bit better

08:00.586 --> 08:02.400
and a little bit more interesting.

08:02.400 --> 08:03.660
And that's been really surprising

08:03.660 --> 08:05.280
and nice to see,

08:05.280 --> 08:07.380
'cause kind of fundamentally an optimist.

08:07.380 --> 08:09.870
So it's nice to not be proven naive,

08:09.870 --> 08:12.030
which a lot of times optimists are.

08:12.030 --> 08:12.863
<v ->Amazing.</v>

08:12.863 --> 08:14.165
Yes.

08:14.165 --> 08:15.706
And so now we've got this perspective

08:15.706 --> 08:16.539
from a technical perspective,

08:16.539 --> 08:17.490
but also from an agency,

08:17.490 --> 08:19.020
which I think is a,

08:19.020 --> 08:21.840
I'm seeing lots and lots of agencies sprout up

08:21.840 --> 08:22.920
in the last two years.

08:22.920 --> 08:23.753
And so, I think

08:23.753 --> 08:26.400
it's a really interesting perspective that you bring.

08:26.400 --> 08:27.630
Alex and I go way back,

08:27.630 --> 08:28.463
so I'm so glad

08:28.463 --> 08:30.360
you were able to join us.

08:30.360 --> 08:31.530
I don't wanna steal your own thunder,

08:31.530 --> 08:33.030
so you go ahead and introduce yourself.

08:33.030 --> 08:34.380
<v ->Thanks so much, Noelle.</v>

08:34.380 --> 08:36.000
It's wonderful to be with all of you.

08:36.000 --> 08:37.440
I'm Alex Swartsel.

08:37.440 --> 08:39.810
I'm at a nonprofit called Jobs For The Future.

08:39.810 --> 08:42.120
And our mission is to transform

08:42.120 --> 08:43.770
education and workforce systems

08:43.770 --> 08:46.860
in pursuit of equitable economic advancement for all.

08:46.860 --> 08:48.090
What we mean by that,

08:48.090 --> 08:49.170
is that the systems

08:49.170 --> 08:51.270
that all of us probably have moved throughout,

08:51.270 --> 08:52.230
whether in the United States

08:52.230 --> 08:53.250
or around the world,

08:53.250 --> 08:54.720
to connect to an education,

08:54.720 --> 08:55.980
to training, and ultimately,

08:55.980 --> 08:58.140
to a quality job and a career

08:58.140 --> 09:00.840
that can sustain us and our families.

09:00.840 --> 09:03.090
Well, too often those systems don't work

09:03.090 --> 09:04.950
as well as they should and they don't talk to one another.

09:04.950 --> 09:06.480
And so, our mission is to make sure

09:06.480 --> 09:07.830
that everybody has access

09:07.830 --> 09:09.330
to the kind of education and training

09:09.330 --> 09:11.250
and to a quality job that will allow them

09:11.250 --> 09:12.510
to support themselves and their families.

09:12.510 --> 09:14.610
Our team focuses specifically on the role

09:14.610 --> 09:16.860
that emerging technology can play in that work.

09:16.860 --> 09:17.693
And we've been heading up

09:17.693 --> 09:19.710
over just the last 18 months or so,

09:19.710 --> 09:21.690
an intensive focus on AI

09:21.690 --> 09:22.620
in the future of work.

09:22.620 --> 09:24.120
And so, I think what we've seen

09:24.120 --> 09:25.620
with a lot of help from Noelle

09:25.620 --> 09:26.520
and others on the team, right.

09:26.520 --> 09:27.510
What we've seen,

09:27.510 --> 09:29.106
I think is in the short-term,

09:29.106 --> 09:30.960
a really intensive focus

09:30.960 --> 09:33.660
on AI competency and skill development.

09:33.660 --> 09:36.060
So just as all of you should have raised your hands

09:36.060 --> 09:37.380
when we asked about

09:37.380 --> 09:39.330
who is developing AI skills?

09:39.330 --> 09:40.470
That's gonna be critical

09:40.470 --> 09:42.900
for every single job across the workforce

09:42.900 --> 09:46.200
because these tools and platforms will be everywhere.

09:46.200 --> 09:47.100
But we're also, I think,

09:47.100 --> 09:48.840
starting to see shifts

09:48.840 --> 09:50.100
in some of the bigger questions

09:50.100 --> 09:52.500
that we're asking about the future of work.

09:52.500 --> 09:55.350
I think in this sort of complex landscape

09:55.350 --> 09:57.000
that we're operating it within,

09:57.000 --> 09:58.350
both from the last panel

09:58.350 --> 10:00.330
where there are some real questions being asked

10:00.330 --> 10:02.280
about potential labor savings

10:02.280 --> 10:04.590
through productivity growth and so forth,

10:04.590 --> 10:07.380
and risks to jobs in that dimension,

10:07.380 --> 10:08.760
but also the opportunities

10:08.760 --> 10:10.530
that others of the panel have spoken about

10:10.530 --> 10:12.840
for more fulfilling and creative roles,

10:12.840 --> 10:15.000
even for job creation in different ways.

10:15.000 --> 10:15.833
And so I think for us,

10:15.833 --> 10:18.510
it boils down to a couple of key questions

10:18.510 --> 10:19.950
that I hope will be part,

10:19.950 --> 10:21.570
not just of this conversation,

10:21.570 --> 10:23.340
but of the whole conversation

10:23.340 --> 10:25.230
around AI long into the future.

10:25.230 --> 10:26.610
And one of those is,

10:26.610 --> 10:27.930
what is the work

10:27.930 --> 10:29.670
that we as a society believe

10:29.670 --> 10:31.920
that only humans can or should do,

10:31.920 --> 10:34.650
whether it's in partnership with AI or alone.

10:34.650 --> 10:35.910
And then secondly,

10:35.910 --> 10:37.560
how can we make sure

10:37.560 --> 10:39.390
that progress in AI

10:39.390 --> 10:42.420
works to ensure that everybody has access

10:42.420 --> 10:44.910
to a livelihood and a quality job?

10:44.910 --> 10:45.960
And that's a standard

10:45.960 --> 10:47.460
by which we need to evaluate AI

10:47.460 --> 10:48.870
and we're not talking enough about that.

10:48.870 --> 10:51.184
So I hope we can get into this, some of that more today.

10:51.184 --> 10:52.017
<v ->Oh my gosh, great.</v>

10:52.017 --> 10:52.850
I love it.

10:52.850 --> 10:53.683
Yes.

10:53.683 --> 10:55.530
Yes, I love that topic.

10:55.530 --> 10:57.030
I hope, I know we're gonna

10:57.030 --> 10:58.290
at least get an opportunity

10:58.290 --> 10:59.123
to talk about it

10:59.123 --> 10:59.956
at the end this week.

10:59.956 --> 11:01.110
Close it out.

11:01.110 --> 11:02.190
So thank you for that.

11:02.190 --> 11:06.090
And Adrian, I think compliments all of us very nicely

11:06.090 --> 11:08.378
because he provides a slightly larger scale

11:08.378 --> 11:09.630
view of the world.

11:09.630 --> 11:11.400
So I'd love the audience to understand

11:11.400 --> 11:12.720
a little bit about what you do

11:12.720 --> 11:15.000
and your view of the workforce.

11:15.000 --> 11:16.980
<v ->Hi, everyone, great to be here.</v>

11:16.980 --> 11:18.150
I'm Adrian McDermott.

11:18.150 --> 11:21.540
I'm the CTO of a software company called Zendesk.

11:21.540 --> 11:23.280
We make customer service software

11:23.280 --> 11:25.533
for about a hundred thousand businesses.

11:26.370 --> 11:28.320
There's four to 5 million people

11:28.320 --> 11:29.640
using our platform every day

11:29.640 --> 11:31.410
to give customer service

11:31.410 --> 11:34.710
to our customer's customers.

11:34.710 --> 11:36.783
I think from an AI point of view,

11:37.800 --> 11:39.060
I really feel like

11:39.060 --> 11:41.340
I'm straddling three different worlds.

11:41.340 --> 11:45.300
One is the builders of software and the technologists.

11:45.300 --> 11:46.796
And I think they are adapting

11:46.796 --> 11:48.903
to this paradigm shift.

11:50.460 --> 11:52.590
And it's an interesting paradigm shift for developers

11:52.590 --> 11:55.770
because for a developer expects

11:55.770 --> 11:56.790
to ask an API

11:56.790 --> 11:58.947
the same question with the same data

11:58.947 --> 12:00.660
and get the same answer.

12:00.660 --> 12:03.060
Unfortunately, LLMs don't behave that way.

12:03.060 --> 12:04.230
Or fortunately.

12:04.230 --> 12:06.900
They're a little more creative than that.

12:06.900 --> 12:08.760
They're unreliable like us,

12:08.760 --> 12:10.560
like me, which is great.

12:10.560 --> 12:12.420
And so training people to adapt to that,

12:12.420 --> 12:14.040
but also then to trust the tools

12:14.040 --> 12:14.940
and use the tools,

12:14.940 --> 12:16.680
is part of what we're doing

12:16.680 --> 12:18.270
and then to build on top of it.

12:18.270 --> 12:20.130
Secondly, in customer service,

12:20.130 --> 12:21.420
it is generally agreed.

12:21.420 --> 12:23.070
I think that customer service is gonna be one

12:23.070 --> 12:24.030
of the first places

12:24.030 --> 12:26.550
where jobs will change.

12:26.550 --> 12:29.010
The nature of work will be different.

12:29.010 --> 12:30.750
Customer service generally scaled

12:30.750 --> 12:33.510
using human power, right.

12:33.510 --> 12:34.343
All of the metrics

12:34.343 --> 12:35.400
of customer service time

12:35.400 --> 12:38.310
to first response, average handle time,

12:38.310 --> 12:41.220
they're all about managing human capital

12:41.220 --> 12:43.110
and human capital time.

12:43.110 --> 12:47.340
The marginal cost of the next AI agent is obviously zero.

12:47.340 --> 12:49.590
And so there are different metrics

12:49.590 --> 12:51.690
and different things that happen and we can,

12:51.690 --> 12:53.190
I think talk about,

12:53.190 --> 12:54.690
it's a core,

12:54.690 --> 12:56.610
I think case and things that are,

12:56.610 --> 12:57.787
it's happening today

12:57.787 --> 12:59.730
where people have been re-skilled

12:59.730 --> 13:01.590
and we're using copilot technologies

13:01.590 --> 13:03.450
and the nature of work is changing.

13:03.450 --> 13:06.543
And then thirdly, actually in my extracurricular life,

13:07.440 --> 13:08.503
I'm on the board of a company

13:08.503 --> 13:10.230
called Be My Eyes,

13:10.230 --> 13:11.430
which is an app

13:11.430 --> 13:13.170
for the blind and partially cited,

13:13.170 --> 13:14.490
what I just wanted to mention that

13:14.490 --> 13:17.460
as it's embedded in your Meta glasses.

13:17.460 --> 13:18.599
<v ->Yes.</v>

13:18.599 --> 13:19.650
<v ->So were you someone without vision</v>

13:19.650 --> 13:21.090
or who needed vision assistance,

13:21.090 --> 13:24.240
you could call for Be My AI to help you,

13:24.240 --> 13:28.380
or for one of the 7 million volunteers

13:28.380 --> 13:29.430
on the platform to come in

13:29.430 --> 13:30.870
and tell you what you are looking at,

13:30.870 --> 13:32.100
how to get a taxi.

13:32.100 --> 13:33.060
Is that taxi free?

13:33.060 --> 13:33.893
These kind of things.

13:33.893 --> 13:35.880
And I think that is a great example

13:35.880 --> 13:40.290
of the way that this technology can really change

13:40.290 --> 13:42.150
the way people live and the accessibility

13:42.150 --> 13:43.230
and the way that they can get around

13:43.230 --> 13:44.310
and experience the world.

13:44.310 --> 13:46.860
And we have to think differently about the apps

13:46.860 --> 13:48.160
that we can build upon it.

13:49.030 --> 13:49.863
<v ->Oh my gosh, I love that.</v>

13:49.863 --> 13:51.660
And I'm a big believer in accessibility.

13:51.660 --> 13:53.100
I feel like it's the tip of the spear

13:53.100 --> 13:55.950
and pushes a lot of really great technology into the world.

13:55.950 --> 13:57.030
So thank you for sharing that.

13:57.030 --> 13:59.850
And yes, I do actually use it often.

13:59.850 --> 14:01.230
I do use it to tell me

14:01.230 --> 14:02.520
when there's a Starbucks nearby,

14:02.520 --> 14:04.980
but still, it's fine.

14:04.980 --> 14:06.840
But I also have a child with Down Syndrome

14:06.840 --> 14:08.060
and so he uses it

14:08.060 --> 14:10.110
in a much more practical way

14:10.110 --> 14:11.340
and it inspires me.

14:11.340 --> 14:13.830
It inspires me that it takes a team

14:13.830 --> 14:15.600
like the one you're talking about,

14:15.600 --> 14:16.433
to actually say, yes,

14:16.433 --> 14:17.580
I'm willing to solve that problem

14:17.580 --> 14:18.990
and I'm willing to build that technology

14:18.990 --> 14:20.760
and then willing to put it into production.

14:20.760 --> 14:21.750
In order to do that though,

14:21.750 --> 14:22.860
the people that do this work

14:22.860 --> 14:24.210
do need to get skilled.

14:24.210 --> 14:25.950
And so you mentioned re-skilling.

14:25.950 --> 14:28.590
I don't have time to ask everybody every question,

14:28.590 --> 14:29.910
so I handpicked the people

14:29.910 --> 14:32.370
that I'm gonna ask this question of.

14:32.370 --> 14:33.540
But Lindsey and Bob,

14:33.540 --> 14:36.090
I'm gonna go to you about re-skilling.

14:36.090 --> 14:36.990
It's a hot topic.

14:36.990 --> 14:38.100
Everyone's talking about re-skilling.

14:38.100 --> 14:38.933
It's in the new,

14:38.933 --> 14:43.560
the EU ACT is presenting a regulation around reskilling,

14:43.560 --> 14:45.240
which I'm happy for,

14:45.240 --> 14:47.880
because I'm an educator, so yay me.

14:47.880 --> 14:49.260
So it's gonna be a good time.

14:49.260 --> 14:52.320
But I would be very curious, not necessarily broadly,

14:52.320 --> 14:53.880
but very specifically, I mean,

14:53.880 --> 14:55.830
especially as a personality,

14:55.830 --> 14:58.620
as someone who is a trusted advisor to communities

14:58.620 --> 15:00.543
through the news work that you do.

15:01.380 --> 15:05.010
And Bob, in your role at the agency,

15:05.010 --> 15:05.970
I would like to understand

15:05.970 --> 15:07.279
what you personally do

15:07.279 --> 15:09.480
to stay skilled up, right.

15:09.480 --> 15:11.160
What advice can we give?

15:11.160 --> 15:14.880
Like how are you just keeping up with the systems

15:14.880 --> 15:16.110
and tools and ideas

15:16.110 --> 15:17.070
that are coming out,

15:17.070 --> 15:19.380
coming fast and furious over the last?

15:19.380 --> 15:20.213
So I'll start with Lindsey

15:20.213 --> 15:21.390
and then Bob, go to you.

15:21.390 --> 15:22.916
<v ->Sure.</v>

15:22.916 --> 15:23.940
So for me, I had to make a point

15:23.940 --> 15:25.980
that every day, part of my day,

15:25.980 --> 15:28.590
I'm carving out to stay up-to-date.

15:28.590 --> 15:30.150
Now part of that is because I need to know

15:30.150 --> 15:32.310
what's going on in the world of AI,

15:32.310 --> 15:34.020
the news world of AI.

15:34.020 --> 15:34.853
But part of it,

15:34.853 --> 15:36.390
it's also that I need to know

15:36.390 --> 15:37.830
not only what I'm talking about,

15:37.830 --> 15:38.910
but also what skill

15:38.910 --> 15:40.320
do I need to learn

15:40.320 --> 15:42.630
so that I'm prepared for that next step.

15:42.630 --> 15:46.860
And I mean, I have vision and some ideas

15:46.860 --> 15:48.570
of what the future's going to look like.

15:48.570 --> 15:50.370
And I really do believe

15:50.370 --> 15:53.700
that we're going to have AI anchors in the future.

15:53.700 --> 15:55.680
And I'm not exactly sure

15:55.680 --> 15:57.240
if it's gonna be just an avatar

15:57.240 --> 16:00.750
or if it will be me as an AI.

16:00.750 --> 16:03.870
And I need to know how to use these tools

16:03.870 --> 16:06.120
to like deep fake myself basically,

16:06.120 --> 16:08.125
so that I can own myself.

16:08.125 --> 16:10.582
<v ->Yes.</v>
<v ->But also think about it,</v>

16:10.582 --> 16:12.510
if I get sick, no one wants to hear a sick anchor.

16:12.510 --> 16:14.850
If I'm coughing or my voice is kind of scratchy

16:14.850 --> 16:16.516
and you're trying to listen to the news in the morning,

16:16.516 --> 16:17.730
it's distracting.

16:17.730 --> 16:18.780
It's distracting to me

16:18.780 --> 16:20.430
to try to read the news that way.

16:20.430 --> 16:21.600
It'd be great for my AI

16:21.600 --> 16:22.980
to just take over that day.

16:22.980 --> 16:24.600
That would be wonderful.

16:24.600 --> 16:27.030
Or also, what if you really love

16:27.030 --> 16:28.080
getting your news from me,

16:28.080 --> 16:30.330
you trust me and my AI can go

16:30.330 --> 16:32.070
all day and all night,

16:32.070 --> 16:33.600
it won't sleep.

16:33.600 --> 16:34.770
But then I'm still human,

16:34.770 --> 16:36.000
so I can still maybe meet

16:36.000 --> 16:37.590
with people in real life.

16:37.590 --> 16:38.423
I can still do

16:38.423 --> 16:40.620
some of the in-person work,

16:40.620 --> 16:43.016
but the sitting at the anchor desk and speaking,

16:43.016 --> 16:45.330
that might become AI.

16:45.330 --> 16:47.430
So I'm actually looking at what skillset

16:47.430 --> 16:48.480
I need to develop

16:48.480 --> 16:49.950
and maybe some of these tools

16:49.950 --> 16:51.900
are in their infancy right now,

16:51.900 --> 16:53.160
but at the very least,

16:53.160 --> 16:54.630
I need to know about them.

16:54.630 --> 16:55.500
So it doesn't mean

16:55.500 --> 16:56.333
that I have to know

16:56.333 --> 16:57.810
how to put the whole car together.

16:57.810 --> 17:00.780
I just need to know that this thing's driving

17:00.780 --> 17:04.530
and then I make a decision about what skill I need.

17:04.530 --> 17:05.670
But I talk to so many people

17:05.670 --> 17:07.590
who are trying to re-skill right now

17:07.590 --> 17:09.984
and trying to pick which part of AI.

17:09.984 --> 17:12.630
It's hard, especially for someone like me

17:12.630 --> 17:15.072
who's interested in all of it.

17:15.072 --> 17:18.090
So, that's partly of,

17:18.090 --> 17:19.680
I'll make some decisions about

17:19.680 --> 17:22.140
what specifically I'm going to learn.

17:22.140 --> 17:23.520
I've taken your bot class

17:23.520 --> 17:25.140
in the past as well,

17:25.140 --> 17:27.843
so I've programmed a bot, which was awesome.

17:28.950 --> 17:30.180
A chat bot I should say.

17:30.180 --> 17:32.000
I would love to program an actual bot,

17:32.000 --> 17:33.750
but I can't do it all.

17:33.750 --> 17:35.520
I have to make some choices.

17:35.520 --> 17:37.890
<v ->Yeah. And I think daily practice is so important,</v>

17:37.890 --> 17:39.270
like making it a daily habit.

17:39.270 --> 17:40.103
I always tell people,

17:40.103 --> 17:41.727
I talk to lots of executives.

17:41.727 --> 17:44.670
People that might be characterized

17:44.670 --> 17:48.240
as part of a silver tsunami that's happening.

17:48.240 --> 17:50.370
Have you heard this term where lots of people

17:50.370 --> 17:52.170
with silver hair are leaving the workforce.

17:52.170 --> 17:53.003
And they're like,

17:53.003 --> 17:54.540
I don't need to know anything about this.

17:54.540 --> 17:56.640
And I'm like, well, it'd be great if you did.

17:56.640 --> 17:58.440
And then I teach them,

17:58.440 --> 18:00.690
I re-skill them not through,

18:00.690 --> 18:05.070
hey, do take this class, listen to this lecture.

18:05.070 --> 18:07.080
I literally do what we do in our bot class

18:07.080 --> 18:08.040
where we bring people in

18:08.040 --> 18:10.110
and we actually have them build a system

18:10.110 --> 18:11.670
for someone they care about,

18:11.670 --> 18:14.040
someone in their ecosystem.

18:14.040 --> 18:15.420
And it is in that awareness

18:15.420 --> 18:16.410
that they get very excited.

18:16.410 --> 18:17.340
I'd love for Bob for you

18:17.340 --> 18:18.540
to talk a little bit about

18:18.540 --> 18:19.610
what you do every day

18:19.610 --> 18:21.990
or what you're thinking about in terms of re-skilling

18:21.990 --> 18:24.622
for those who are in a similar role.

18:24.622 --> 18:25.455
<v ->Yeah.</v>

18:25.455 --> 18:27.360
So for anyone trying to keep up

18:27.360 --> 18:28.710
with all the technology

18:28.710 --> 18:31.500
and changes that are happening, just stop.

18:31.500 --> 18:33.150
'Cause my wife works in AI,

18:33.150 --> 18:33.990
I work in AI,

18:33.990 --> 18:35.490
I talk about AI all day.

18:35.490 --> 18:37.140
My team talks to me about AI.

18:37.140 --> 18:38.730
People ask me questions about it all day,

18:38.730 --> 18:40.230
and I haven't even scratched the surface.

18:40.230 --> 18:41.340
It's just impossible right now.

18:41.340 --> 18:42.740
It's moving way too quickly.

18:43.680 --> 18:44.880
I think what we try to do

18:44.880 --> 18:46.950
is take what we know

18:46.950 --> 18:48.090
about the work that we're doing,

18:48.090 --> 18:48.990
about what we're building,

18:48.990 --> 18:50.070
about our business strategy

18:50.070 --> 18:51.360
and apply the technology

18:51.360 --> 18:52.710
as well as we can

18:52.710 --> 18:56.740
to reach the goals that we have

18:58.260 --> 19:00.210
that we had set for ourselves before.

19:00.210 --> 19:02.280
I think, I had talked to somebody about this before,

19:02.280 --> 19:03.900
just using the technology is like getting

19:03.900 --> 19:05.820
in a fast car and driving nowhere.

19:05.820 --> 19:07.230
Like you're not gonna get anywhere,

19:07.230 --> 19:08.670
you're not gonna know where you are

19:08.670 --> 19:09.540
when you get there.

19:09.540 --> 19:11.490
You want a direction that you want to go.

19:11.490 --> 19:14.520
And so concentrating on that is I think the best way

19:14.520 --> 19:15.990
to really get your hands around

19:15.990 --> 19:17.670
a lot of this new technology.

19:17.670 --> 19:18.870
As far as re-skilling,

19:18.870 --> 19:20.700
like from a personal level,

19:20.700 --> 19:22.050
I don't think of it

19:22.050 --> 19:24.616
as re-skilling as much as expanding

19:24.616 --> 19:26.550
my knowledge into areas

19:26.550 --> 19:27.990
that I didn't think I had time

19:27.990 --> 19:29.940
to really get into before.

19:29.940 --> 19:32.400
So I work at a creative agency,

19:32.400 --> 19:34.207
but we were acquired,

19:34.207 --> 19:35.520
we were a data and engineering agency before,

19:35.520 --> 19:36.870
so I haven't worked with creatives

19:36.870 --> 19:41.730
and that was just an interesting change.

19:41.730 --> 19:43.616
A lot of engineers working with creatives.

19:43.616 --> 19:45.450
There's sometimes some friction there.

19:45.450 --> 19:48.660
But now I can really use

19:48.660 --> 19:49.493
some of these tools,

19:49.493 --> 19:50.880
ChatGPT, being one of them,

19:50.880 --> 19:52.650
but also the tools that they're asking me about

19:52.650 --> 19:53.483
to get an idea

19:53.483 --> 19:54.660
of what their workflow is,

19:54.660 --> 19:56.400
how they think about the work that they're doing.

19:56.400 --> 19:57.900
And so when I talk to them,

19:57.900 --> 20:01.080
I have a much more universal idea

20:01.080 --> 20:02.730
of how they think about their work.

20:02.730 --> 20:04.590
And so we can start to talk on the same level

20:04.590 --> 20:06.510
that we weren't able to talk about before.

20:06.510 --> 20:08.400
And just me, staying humble about

20:08.400 --> 20:11.070
what I don't know and realizing that the way

20:11.070 --> 20:12.068
that I speak to people

20:12.068 --> 20:13.969
before was really like,

20:13.969 --> 20:16.260
just thinking that you need to speak

20:16.260 --> 20:17.100
the most about the stuff

20:17.100 --> 20:18.390
that you know the most about,

20:18.390 --> 20:20.370
is probably not the best way to communicate.

20:20.370 --> 20:22.290
And now I can start talking the way

20:22.290 --> 20:23.880
that they're used to talking about,

20:23.880 --> 20:24.713
or maybe they're thinking

20:24.713 --> 20:26.580
about their work in a way

20:26.580 --> 20:28.170
that I just wasn't able to before.

20:28.170 --> 20:30.135
<v ->Yeah. I love that closing the gap.</v>

20:30.135 --> 20:31.320
Like in these conversations,

20:31.320 --> 20:33.150
many of us have been in that situation

20:33.150 --> 20:34.350
where we come from our perspective

20:34.350 --> 20:36.180
and then we talk to someone and you're like,

20:36.180 --> 20:39.060
why don't you understand what I'm saying?

20:39.060 --> 20:40.500
So it's really great to have a tool

20:40.500 --> 20:42.120
that can articulate that

20:42.120 --> 20:43.680
and especially in something

20:43.680 --> 20:44.850
like a Microsoft copilot

20:44.850 --> 20:47.220
where it can actually help you craft emails

20:47.220 --> 20:49.020
contextually for the team

20:49.020 --> 20:49.853
that you're talking to.

20:49.853 --> 20:51.519
It's really exciting stuff. So thank you for that, Bob.

20:51.519 --> 20:52.410
That's amazing.

20:52.410 --> 20:53.730
So I'm gonna shift to another question

20:53.730 --> 20:55.020
and I'm actually gonna focus,

20:55.020 --> 20:56.130
I didn't realize I put you both together,

20:56.130 --> 20:57.480
but you're both gonna be answering this question,

20:57.480 --> 21:00.150
so I'll give you a chance to think about it.

21:00.150 --> 21:02.550
But this question is more about

21:02.550 --> 21:04.620
kind of the future job market

21:04.620 --> 21:08.370
and what you're thinking about in that area.

21:08.370 --> 21:11.160
Like how are you preparing yourself,

21:11.160 --> 21:12.840
but also your teams

21:12.840 --> 21:14.130
and for you, Alex,

21:14.130 --> 21:16.650
maybe like, the work that you're doing,

21:16.650 --> 21:17.940
I think it'd be nice to see

21:17.940 --> 21:19.005
a little bit behind the curtain

21:19.005 --> 21:19.890
in some of the conversations

21:19.890 --> 21:20.723
you're having about like,

21:20.723 --> 21:21.556
how does this actually work

21:21.556 --> 21:22.590
inside of a large business

21:22.590 --> 21:24.990
where you're thinking about lots of people,

21:24.990 --> 21:26.610
what is your-

21:26.610 --> 21:28.981
I don't know either projections or current plans

21:28.981 --> 21:30.960
for how are you going to tackle

21:30.960 --> 21:32.673
this need to skill everyone up?

21:33.990 --> 21:35.250
<v ->I'm happy to start with that</v>

21:35.250 --> 21:36.300
and to talk both about

21:36.300 --> 21:37.410
how we're thinking about it

21:37.410 --> 21:38.700
within jobs for the future,

21:38.700 --> 21:40.170
but also how we're engaging

21:40.170 --> 21:41.820
with our partners across the ecosystem

21:41.820 --> 21:44.970
who are not just major employers and technology companies,

21:44.970 --> 21:48.000
but colleges, universities, community-based organizations

21:48.000 --> 21:50.460
and others who are really wrestling with this.

21:50.460 --> 21:51.330
So for ourselves,

21:51.330 --> 21:53.820
I think we're trying to both ask the questions

21:53.820 --> 21:54.930
about where we can start

21:54.930 --> 21:58.410
to leverage these tools today using piloting approaches

21:58.410 --> 21:59.243
as many of you all

21:59.243 --> 22:00.420
have done as well,

22:00.420 --> 22:03.210
but with a really intense focus on living into our values

22:03.210 --> 22:05.430
as a nonprofit that is focused on this space

22:05.430 --> 22:06.570
and the future of work.

22:06.570 --> 22:08.100
And on this question

22:08.100 --> 22:10.080
of how we're building foundational AI

22:10.080 --> 22:11.670
competency skills amongst our teams.

22:11.670 --> 22:13.988
So I'll give you just one example. We have a pilot starting

22:13.988 --> 22:15.690
just in a couple of weeks

22:15.690 --> 22:17.700
and as we're not only taking applications

22:17.700 --> 22:19.560
from across the entire organization,

22:19.560 --> 22:21.450
every level, every department,

22:21.450 --> 22:25.230
so that this rollout is not siloed in any way,

22:25.230 --> 22:27.270
but we are also making it a requirement

22:27.270 --> 22:29.820
that people engage in AI competency training

22:29.820 --> 22:31.140
before they can start.

22:31.140 --> 22:32.400
Because we know that

22:32.400 --> 22:33.510
and at least are starting

22:33.510 --> 22:35.276
to hear some inklings

22:35.276 --> 22:36.960
that you don't have to worry

22:36.960 --> 22:38.280
about deeply understanding AI.

22:38.280 --> 22:39.210
You just need to understand

22:39.210 --> 22:40.650
how to use this one tool

22:40.650 --> 22:41.880
and you'll be fine.

22:41.880 --> 22:43.320
But because we know this technology

22:43.320 --> 22:44.550
is moving so quickly

22:44.550 --> 22:45.720
and so much of the way

22:45.720 --> 22:47.190
in which you can use it effectively,

22:47.190 --> 22:49.170
depends on a deeper understanding

22:49.170 --> 22:51.030
of what it's good at, what it's not,

22:51.030 --> 22:52.590
what its limitations are today,

22:52.590 --> 22:54.720
what its capabilities might be tomorrow

22:54.720 --> 22:56.370
that we believe strongly that everybody needs

22:56.370 --> 22:58.350
to have that foundational level of understanding.

22:58.350 --> 22:59.183
And then in terms

22:59.183 --> 23:00.780
of how we're talking about it to the field,

23:00.780 --> 23:02.100
a lot of it does center

23:02.100 --> 23:04.440
on how we believe jobs may change

23:04.440 --> 23:06.240
and the skills that are going to be in demand,

23:06.240 --> 23:08.670
especially where we need to support

23:08.670 --> 23:11.250
that kind of skill development for populations

23:11.250 --> 23:12.780
that may have experienced barriers

23:12.780 --> 23:14.430
to economic advancement in the past.

23:14.430 --> 23:16.920
Whether that's because people have criminal records

23:16.920 --> 23:19.710
or people don't have bachelor's degrees, for example.

23:19.710 --> 23:20.910
And so, I mentioned before

23:20.910 --> 23:22.800
and everyone is experiencing it,

23:22.800 --> 23:26.280
that there is an intensive near term focus on AI competency,

23:26.280 --> 23:27.450
which is great for all the reasons

23:27.450 --> 23:28.770
that we've just talked about.

23:28.770 --> 23:29.910
But we're talking a lot

23:29.910 --> 23:32.070
to the field about a deeper layer

23:32.070 --> 23:34.560
of changes in demand skills.

23:34.560 --> 23:36.870
We believe that human skills,

23:36.870 --> 23:38.220
what we used to call soft skills,

23:38.220 --> 23:39.300
being able to collaborate,

23:39.300 --> 23:42.480
to communicate effectively with a wide variety of audiences,

23:42.480 --> 23:45.480
to be able to engage cross-functionally amongst teams,

23:45.480 --> 23:47.070
to use critical thinking skills,

23:47.070 --> 23:48.690
so that you can evaluate the outputs

23:48.690 --> 23:50.910
of AI tools effectively and know

23:50.910 --> 23:52.080
if an output is the right one

23:52.080 --> 23:53.820
for the decision you're trying to make,

23:53.820 --> 23:55.830
those skills are going to be essential.

23:55.830 --> 23:57.420
But we also see others as well,

23:57.420 --> 23:58.969
whether that's entrepreneurship.

23:58.969 --> 24:00.570
Somebody said earlier today,

24:00.570 --> 24:02.370
all engineers need to be entrepreneurs.

24:02.370 --> 24:04.170
We think every worker needs

24:04.170 --> 24:05.580
to have entrepreneurship skills

24:05.580 --> 24:08.422
because that will allow people to spot opportunities

24:08.422 --> 24:10.830
to not just have productivity gains

24:10.830 --> 24:11.760
that in the long run,

24:11.760 --> 24:14.580
could potentially eliminate jobs or risk jobs.

24:14.580 --> 24:18.540
But for the creation of new business value of new products

24:18.540 --> 24:21.180
and services, new businesses and ideas,

24:21.180 --> 24:23.100
we're already starting anecdotally

24:23.100 --> 24:27.330
to see entrepreneurs, small business owners using AI tools

24:27.330 --> 24:29.220
to dramatically uplevel their business,

24:29.220 --> 24:31.590
to be able to grow in ways that they couldn't

24:31.590 --> 24:33.900
because of capital constraints or other factors.

24:33.900 --> 24:35.310
And that's really exciting

24:35.310 --> 24:37.980
because that ultimately redown to job creation.

24:37.980 --> 24:40.260
So what we're trying to do within our ecosystem

24:40.260 --> 24:41.700
is just to push the boundaries

24:41.700 --> 24:43.020
of the conversation a little bit to say,

24:43.020 --> 24:43.853
here's some things

24:43.853 --> 24:45.750
that you might not be thinking about today,

24:45.750 --> 24:46.830
but that you should,

24:46.830 --> 24:47.970
whether that's skill development,

24:47.970 --> 24:50.070
whether it's other opportunities to use AI

24:50.070 --> 24:53.040
to generate economic opportunity and mobility

24:53.040 --> 24:54.812
because it's moving so fast

24:54.812 --> 24:57.660
that if we don't act in those ways today,

24:57.660 --> 24:58.950
if we don't put those pieces in place,

24:58.950 --> 25:00.180
we're gonna get left behind.

25:00.180 --> 25:01.013
<v ->Awesome, I love it.</v>

25:01.013 --> 25:01.920
Thank you very much.

25:01.920 --> 25:03.930
Adrian, what are your thoughts on it?

25:03.930 --> 25:05.253
<v ->Well, I think about the way</v>

25:05.253 --> 25:08.916
that we speak specifically to our customers

25:08.916 --> 25:10.980
and they're probably driving

25:10.980 --> 25:13.470
some mission around customer service

25:13.470 --> 25:16.560
and a core principle that we remind them of,

25:16.560 --> 25:18.420
is that no one ever says,

25:18.420 --> 25:19.253
oh, you know what,

25:19.253 --> 25:20.130
I have enough customer service.

25:20.130 --> 25:22.200
I don't really need anymore, right.

25:22.200 --> 25:24.570
And so, the opportunity here,

25:24.570 --> 25:26.040
I think it's easy to swing

25:26.040 --> 25:29.043
towards cost saving and reduction of force.

25:30.480 --> 25:31.590
A lot of people are stepping away

25:31.590 --> 25:33.510
from seasonal hiring for Black Friday

25:33.510 --> 25:34.343
and these kind of things,

25:34.343 --> 25:36.450
'cause they working towards automation.

25:36.450 --> 25:38.880
But our focus with our customers

25:38.880 --> 25:40.620
is really directing them

25:40.620 --> 25:42.900
towards the experiences that they want to build.

25:42.900 --> 25:44.190
What are the customer journeys

25:44.190 --> 25:46.680
and the experiences you want your customers to have?

25:46.680 --> 25:49.200
How do you think your brand can differentiate

25:49.200 --> 25:50.970
when everyone can have really

25:50.970 --> 25:53.880
high quality service available 24/7,

25:53.880 --> 25:56.610
because it's automated and zero marginal cost.

25:56.610 --> 25:59.280
Like what are you gonna do to differentiate?

25:59.280 --> 26:01.980
And since the introduction

26:01.980 --> 26:04.680
of the telephone brought with it,

26:04.680 --> 26:06.600
the removal of face-to-face service,

26:06.600 --> 26:10.290
but it enabled us to have scripts and queues

26:10.290 --> 26:11.123
and all these rituals

26:11.123 --> 26:13.350
of customer support that came in

26:13.350 --> 26:15.780
and people didn't necessarily like them, right.

26:15.780 --> 26:16.845
We hit zero

26:16.845 --> 26:18.900
because we want the human touch

26:18.900 --> 26:21.450
or because we're in a moment of panic or stress

26:21.450 --> 26:22.410
or we need empathy

26:22.410 --> 26:24.120
or we don't have enough trust

26:24.120 --> 26:25.560
in the right answer.

26:25.560 --> 26:28.980
And I think guiding people towards seeing

26:28.980 --> 26:31.650
how AI is a tool,

26:31.650 --> 26:36.180
it's a tool that can help further your advancement

26:36.180 --> 26:37.440
towards your ultimate goals.

26:37.440 --> 26:38.790
It's a tool that can help you grow

26:38.790 --> 26:41.310
your business by connecting better,

26:41.310 --> 26:44.730
have providing better service, cross-selling, upselling,

26:44.730 --> 26:46.590
doing all the things that you want to do,

26:46.590 --> 26:47.790
and really re-skilling

26:47.790 --> 26:49.290
and deploying the human population

26:49.290 --> 26:50.340
where they're best.

26:50.340 --> 26:52.740
People are not at their best explaining to other people

26:52.740 --> 26:54.630
how to change their password.

26:54.630 --> 26:57.540
People are at their best connecting with humans

26:57.540 --> 26:59.550
in these human interactive tasks

26:59.550 --> 27:02.670
that require judgment and socialization.

27:02.670 --> 27:04.260
And I think as long as we remember that

27:04.260 --> 27:06.570
as we design these systems of interaction

27:06.570 --> 27:09.570
and however it is we're deploying AI,

27:09.570 --> 27:11.010
remember what we're good at,

27:11.010 --> 27:13.230
that is to a certain extent,

27:13.230 --> 27:17.160
I'm gonna say right now, irreplaceable anyway.

27:17.160 --> 27:18.390
I think as long as we remember that

27:18.390 --> 27:21.660
we can help drive our businesses,

27:21.660 --> 27:23.550
our organizations towards a mission

27:23.550 --> 27:27.480
and make sure that we're keeping the human touch.

27:27.480 --> 27:28.313
<v ->Absolutely.</v>

27:28.313 --> 27:29.146
And I've worked a lot

27:29.146 --> 27:30.780
in the context center space

27:30.780 --> 27:32.100
and I think it's very interesting

27:32.100 --> 27:33.390
because it's one of those areas

27:33.390 --> 27:35.070
that's got high volatility

27:35.070 --> 27:37.710
in maintaining people in the role

27:37.710 --> 27:38.700
for a lot of reasons

27:38.700 --> 27:40.050
that you had mentioned

27:40.050 --> 27:45.000
and that one of the most financially impactful strategies

27:45.000 --> 27:47.850
organizations implemented over the last year.

27:47.850 --> 27:48.683
As a matter of fact,

27:48.683 --> 27:50.910
we did a article in Harvard Business Review,

27:50.910 --> 27:52.500
happy to share it with you all,

27:52.500 --> 27:53.550
but it talked about like

27:53.550 --> 27:55.920
the number one thing was helping the helper,

27:55.920 --> 27:58.230
was leveraging your new found knowledge

27:58.230 --> 28:00.180
and skills in AI to actually build systems

28:00.180 --> 28:01.290
that help the people

28:01.290 --> 28:02.550
that are talking to the humans.

28:02.550 --> 28:03.390
That you're right.

28:03.390 --> 28:06.900
When my dad lives with me,

28:06.900 --> 28:09.240
my dad, he never wants,

28:09.240 --> 28:10.920
I mean, he talks to Alexa every day,

28:10.920 --> 28:12.480
but not about anything he cares about.

28:12.480 --> 28:14.100
When it comes to something he cares about,

28:14.100 --> 28:15.150
he wants to talk to a human

28:15.150 --> 28:17.460
and he's the first one to eject himself

28:17.460 --> 28:18.720
out of the IVR system

28:18.720 --> 28:21.810
we've painfully created over the last 20 years.

28:21.810 --> 28:23.520
So we're moving into a part

28:23.520 --> 28:25.473
of the session that I like.

28:26.867 --> 28:28.140
It's a little black mirrory,

28:28.140 --> 28:29.430
but I like it,

28:29.430 --> 28:32.040
because we'll end somewhere hopefully nice.

28:32.040 --> 28:34.050
But I'd like to start by sharing with you,

28:34.050 --> 28:36.450
some of you saw me bring a stuffed tiger.

28:36.450 --> 28:38.670
It is an emotional support tiger, yes.

28:38.670 --> 28:41.970
But I bring it on stage as a reminder

28:41.970 --> 28:46.230
because as companies start investing in this technology,

28:46.230 --> 28:47.220
his name's Bruiser.

28:47.220 --> 28:49.320
I know someone just asked that in their mind.

28:49.320 --> 28:51.660
So yeah, it's Bruiser.

28:51.660 --> 28:53.430
And one of the things

28:53.430 --> 28:55.830
that often happens is that people adopt AI

28:55.830 --> 28:58.230
like they are adopting a baby tiger.

28:58.230 --> 29:00.332
Like they get a baby tiger and they're like, oh my gosh,

29:00.332 --> 29:01.590
it's so cute and adorable,

29:01.590 --> 29:03.256
and I love it. And it can do this thing

29:03.256 --> 29:04.089
and I wanna take a picture

29:04.089 --> 29:05.755
and can I join that team? That'd be fun.

29:05.755 --> 29:08.760
It's very, very enthusiastic, hype.

29:08.760 --> 29:10.350
It's why there's a cycle around it,

29:10.350 --> 29:12.517
the hype cycle, right.

29:12.517 --> 29:15.600
But over time, as that tiger begins to grow,

29:15.600 --> 29:18.870
it is 100% dependent on you,

29:18.870 --> 29:22.830
on the workers to actually train that tiger

29:22.830 --> 29:25.980
to become a confident, safe, secure way

29:25.980 --> 29:28.680
to help amplify the work that people do every day.

29:28.680 --> 29:30.180
And so, it becomes a reminder to me,

29:30.180 --> 29:31.830
I have people give me baby tigers,

29:31.830 --> 29:33.690
I carry one around with me all the time

29:33.690 --> 29:35.250
to remind me that every time

29:35.250 --> 29:36.510
we start an AI journey,

29:36.510 --> 29:37.680
it starts off with something

29:37.680 --> 29:39.060
that seems pretty cool,

29:39.060 --> 29:41.040
but could just as easily hurt us.

29:41.040 --> 29:42.420
And so I share that

29:42.420 --> 29:44.700
because I'd like a couple of people,

29:44.700 --> 29:46.080
I mean, if you wanna jump in

29:46.080 --> 29:47.932
some others who don't get picked,

29:47.932 --> 29:49.560
it's a good topic,

29:49.560 --> 29:51.751
but I wanna just have a couple people share

29:51.751 --> 29:54.390
some of the biggest blunders they've seen.

29:54.390 --> 29:55.380
As a matter of fact,

29:55.380 --> 29:56.940
Brian, we talked about it.

29:56.940 --> 30:00.480
So I think one of those blunders would be great.

30:00.480 --> 30:03.300
And then I'm also going to have, Adrian,

30:03.300 --> 30:07.350
I know you got some good scary stories in customer service,

30:07.350 --> 30:08.760
so I just thought it'd be good for you

30:08.760 --> 30:10.530
to see kind of the worst of it.

30:10.530 --> 30:12.990
Like how does this not go well?

30:12.990 --> 30:15.064
So maybe Brian, you can get started with that.

30:15.064 --> 30:15.897
<v ->Sure.</v>

30:15.897 --> 30:16.730
From a couple different angles

30:16.730 --> 30:17.580
I can think about.

30:17.580 --> 30:21.420
I mean, just from like the software development angle,

30:21.420 --> 30:26.420
there's driven by the need to compete

30:26.820 --> 30:28.380
and hype and things like that.

30:28.380 --> 30:30.030
Some products will get rolled out

30:31.200 --> 30:33.720
without fully developing guardrails

30:33.720 --> 30:35.613
that might be needed.

30:36.570 --> 30:38.370
And the most extreme

30:38.370 --> 30:40.290
or maybe famous examples of that

30:40.290 --> 30:43.230
might be things like facial recognition

30:43.230 --> 30:45.030
that depending on the color of someone's skin,

30:45.030 --> 30:46.830
might not recognize 'em or confuse them,

30:46.830 --> 30:47.820
and things like that

30:47.820 --> 30:50.103
that everyone can really connect with.

30:54.570 --> 30:58.020
To me, from the software development angle,

30:58.020 --> 30:59.362
that's probably one thing

30:59.362 --> 31:00.879
that I think of.

31:00.879 --> 31:02.490
The example I know

31:02.490 --> 31:04.560
that that not to be mysterious

31:04.560 --> 31:05.580
that we had been talking about

31:05.580 --> 31:10.377
was the hallucinated cases citations.

31:11.505 --> 31:13.405
And just for anyone who's not familiar

31:16.845 --> 31:19.140
with the story, with these circumstances is,

31:19.140 --> 31:19.973
there was a lawyer

31:19.973 --> 31:21.880
who was suing an airline in New York

31:23.040 --> 31:24.840
and he used ChatGPT

31:24.840 --> 31:26.430
to write his legal brief

31:26.430 --> 31:28.230
and then he filed it with a court

31:28.230 --> 31:31.004
and it contained made up cases

31:31.004 --> 31:31.980
(Brian coughs)

31:31.980 --> 31:34.110
and he was actually given an opportunity

31:34.110 --> 31:35.730
to correct the brief and didn't.

31:35.730 --> 31:37.050
So he ended up getting sanctioned

31:37.050 --> 31:39.120
and suspended from practicing

31:39.120 --> 31:40.050
for like five years

31:40.050 --> 31:42.540
and they put out a press release about,

31:42.540 --> 31:43.890
they wanted to make an example.

31:43.890 --> 31:46.101
So, learning-

31:46.101 --> 31:46.934
<v ->Fire.</v>

31:46.934 --> 31:47.767
<v ->Yeah.</v>

31:47.767 --> 31:49.750
Learning by fire there.

31:49.750 --> 31:50.583
(Noelle chuckles)

31:50.583 --> 31:54.030
But I guess, those are kind of two examples.

31:54.030 --> 31:56.100
One other one that I could maybe throw in there

31:56.100 --> 31:58.779
just because spend a lot of time

31:58.779 --> 32:03.450
with my trade association doing policy advocacy,

32:03.450 --> 32:07.110
mostly with the federal government is,

32:07.110 --> 32:08.760
I think from that perspective,

32:08.760 --> 32:11.643
from the people setting these rules,

32:12.690 --> 32:15.090
there has been definitely

32:15.090 --> 32:16.200
over the last year

32:16.200 --> 32:17.160
and a half two years,

32:17.160 --> 32:20.440
a real rush to jump in and regulate

32:21.450 --> 32:26.450
and the example that I can give there is,

32:26.460 --> 32:30.840
there was a non-discrimination rule

32:30.840 --> 32:32.730
under the Affordable Care Act

32:32.730 --> 32:34.210
that was put into place

32:35.160 --> 32:37.260
by the Health and Human Services department,

32:37.260 --> 32:40.200
which put strict liability on any doctor

32:40.200 --> 32:42.420
who uses AI defined super broadly.

32:42.420 --> 32:45.360
Like even using the sum function

32:45.360 --> 32:47.190
in an Excel spreadsheet potentially,

32:47.190 --> 32:48.540
could meet this definition.

32:50.880 --> 32:52.380
So if they use this AI

32:52.380 --> 32:53.790
then they face strict liability.

32:53.790 --> 32:57.120
And I think there's a negative impact on the work.

32:57.120 --> 32:59.195
It's a great reason to say no,

32:59.195 --> 33:01.860
when you talk to your internal counsel

33:01.860 --> 33:04.920
or something like that for a lawyer to say,

33:04.920 --> 33:05.850
no, the risk is too high,

33:05.850 --> 33:06.683
just don't use it

33:06.683 --> 33:08.193
and not pick up the tools at all.

33:09.467 --> 33:13.080
So we're always trying to encourage

33:13.080 --> 33:14.820
regulations being put into place

33:14.820 --> 33:16.740
to be technology neutral

33:16.740 --> 33:21.000
and based on reasonably expected

33:21.000 --> 33:23.580
or demonstrated harms rather than hypotheticals.

33:23.580 --> 33:24.870
But three different angles

33:24.870 --> 33:26.224
I thought I threw out there.

33:26.224 --> 33:27.057
<v ->Yeah, I love it.</v>

33:27.057 --> 33:29.250
I love it. I mean, so I have baby tiger moments on LinkedIn.

33:29.250 --> 33:30.510
I post baby tiger moments

33:30.510 --> 33:31.440
of all of these.

33:31.440 --> 33:34.350
There are hundreds of very reputable companies

33:34.350 --> 33:36.420
going into production with nonsense

33:36.420 --> 33:38.520
that hurts their companies, their clients.

33:38.520 --> 33:39.840
And what I say is like,

33:39.840 --> 33:40.800
yeah, it's sad to watch,

33:40.800 --> 33:42.120
but it's extremely valuable

33:42.120 --> 33:44.070
for you all as like people

33:44.070 --> 33:45.060
who will do this work,

33:45.060 --> 33:46.590
we can learn from them.

33:46.590 --> 33:48.660
At least, we could learn from them.

33:48.660 --> 33:50.610
Adrian, any good stories come to mind

33:50.610 --> 33:51.570
that you'd like to share with us

33:51.570 --> 33:54.062
that wouldn't hurt you too hard to tell.

33:54.062 --> 33:54.895
(Noelle chuckles)

33:54.895 --> 33:56.100
<v ->Well, firstly, I should acknowledge</v>

33:56.100 --> 33:57.150
that my name is Adrian

33:57.150 --> 33:59.419
and I have deployed some **** bots.

33:59.419 --> 34:01.085
(All chuckles) And you may have used them

34:01.085 --> 34:02.624
and I apologize, I'm deservedly.

34:02.624 --> 34:03.457
<v ->Hi, Adrian.</v>

34:03.457 --> 34:04.410
(All chuckles)

34:04.410 --> 34:06.150
<v ->But in all seriousness,</v>

34:06.150 --> 34:11.150
I think people get excited about the cost saving aspect

34:11.490 --> 34:14.470
or about some other efficiency aspect of technology

34:15.330 --> 34:17.910
and then they create bad experiences

34:17.910 --> 34:19.740
and they generally get found out.

34:19.740 --> 34:21.390
That's category one

34:21.390 --> 34:23.370
of what can go wrong, I think.

34:23.370 --> 34:24.203
And it's the one,

34:24.203 --> 34:26.000
a lot of us are familiar with, right.

34:28.332 --> 34:30.150
Our first AI model we released in 2014,

34:30.150 --> 34:32.760
it was trained on a hundred thousand tickets.

34:32.760 --> 34:34.890
GPT-4 is trained on the entire internet.

34:34.890 --> 34:35.723
Big difference.

34:35.723 --> 34:37.114
<v ->Yeah.</v>

34:37.114 --> 34:37.947
<v ->It understands a lot more</v>

34:37.947 --> 34:38.780
of what people are saying to it,

34:38.780 --> 34:39.613
much better experience, right.

34:39.613 --> 34:42.570
And so understanding the limits of your technology

34:42.570 --> 34:44.670
and what you can do to deploy it, really important.

34:44.670 --> 34:46.560
That's category one disaster.

34:46.560 --> 34:49.290
Category two, I think would be politely formulated

34:49.290 --> 34:51.510
as mess around and find out, right.

34:51.510 --> 34:54.390
You are like an extreme risk taker company

34:54.390 --> 34:55.500
and you're like, ah,

34:55.500 --> 34:56.970
this is really cool.

34:56.970 --> 34:59.070
I'm having a little nerdgasm over the way,

34:59.070 --> 35:00.570
it answers my questions.

35:00.570 --> 35:03.090
Let's just put it live and see how it goes.

35:03.090 --> 35:05.430
There was another airline example actually,

35:05.430 --> 35:07.860
an airline that did that and GPT-4,

35:07.860 --> 35:09.060
if you ask it a question,

35:09.060 --> 35:12.000
it is sort of trying to generate the next token,

35:12.000 --> 35:13.770
which gives you the most viable answer.

35:13.770 --> 35:14.603
So if you ask it,

35:14.603 --> 35:16.320
what is your bereavement policy?

35:16.320 --> 35:17.880
It's like, well, you're a national airline,

35:17.880 --> 35:20.257
you probably have a bereavement policy.

35:20.257 --> 35:21.090
If someone is bereaved,

35:21.090 --> 35:23.400
they can book and change a ticket with no fees.

35:23.400 --> 35:26.100
And so it told the user something plausible,

35:26.100 --> 35:29.283
it gives the most plausible answer, not correct.

35:30.600 --> 35:32.970
And ended, I believe in a class action lawsuit,

35:32.970 --> 35:33.870
if I'm not mistaken.

35:33.870 --> 35:34.703
<v ->Yes.</v>

35:34.703 --> 35:37.230
<v ->And so, I think you kind of dance</v>

35:37.230 --> 35:39.150
between those two sides of the equation.

35:39.150 --> 35:41.580
You wanna be forward thinking,

35:41.580 --> 35:43.380
you wanna deploy technology,

35:43.380 --> 35:46.950
you also don't want to give people terrible experiences

35:46.950 --> 35:48.780
and gate the thing too much

35:48.780 --> 35:49.650
and kind of do that.

35:49.650 --> 35:53.220
And I think the happy path in the middle

35:53.220 --> 35:55.590
is one that is becoming much clearer

35:55.590 --> 35:58.080
and thankfully, the technology gets better

35:58.080 --> 36:00.000
basically every month

36:00.000 --> 36:02.160
and it's becoming much easier to achieve.

36:02.160 --> 36:02.993
<v ->Yeah, amazing.</v>

36:02.993 --> 36:04.313
I love it.

36:04.313 --> 36:05.146
I mean it's terrifying

36:05.146 --> 36:06.720
but exciting all at the same time.

36:06.720 --> 36:08.460
So as we close out the panel,

36:08.460 --> 36:09.780
I always like to end

36:09.780 --> 36:13.290
with hopefully, some practical ideas about

36:13.290 --> 36:16.980
how we see the future of the workforce.

36:16.980 --> 36:19.470
I know personally, I work with lots of clients.

36:19.470 --> 36:21.210
We have an AI accelerator,

36:21.210 --> 36:22.470
we take 'em in 90 days.

36:22.470 --> 36:25.230
We go from in enthusiasm to execution,

36:25.230 --> 36:26.580
which is my new book,

36:26.580 --> 36:27.720
enthusiasm to execution,

36:27.720 --> 36:29.670
which means we start with an idea,

36:29.670 --> 36:30.510
then we build a model

36:30.510 --> 36:32.670
and then we deploy it in 90 days.

36:32.670 --> 36:34.770
The way we do that successfully

36:34.770 --> 36:37.050
is through a concept known as red teaming.

36:37.050 --> 36:39.420
And it literally is doing what we did up here,

36:39.420 --> 36:40.620
bringing together a bunch

36:40.620 --> 36:42.300
of very different perspectives

36:42.300 --> 36:44.790
and having them actually work with a model

36:44.790 --> 36:48.450
to ensure that you don't deploy it prematurely.

36:48.450 --> 36:49.470
And if you do deploy it,

36:49.470 --> 36:50.370
you deploy it to people

36:50.370 --> 36:52.020
that'll give you good feedback.

36:52.020 --> 36:55.620
These are very important, I think processes,

36:55.620 --> 36:56.550
but what I'd like to do

36:56.550 --> 36:58.080
is have every person on the panel

36:58.080 --> 37:00.420
kind of think about a use case

37:00.420 --> 37:02.910
in that maybe they've thought about,

37:02.910 --> 37:04.050
I don't know, 10 years ago

37:04.050 --> 37:07.470
and because of technology, because of resources,

37:07.470 --> 37:08.460
they couldn't get it done.

37:08.460 --> 37:09.293
Like so many times,

37:09.293 --> 37:10.126
we have a dream

37:10.126 --> 37:10.959
like I'm gonna translate

37:10.959 --> 37:12.510
every piece of content I've ever written.

37:12.510 --> 37:13.920
Oh wait, that's hard, nevermind.

37:13.920 --> 37:15.420
And we forget about doing it.

37:15.420 --> 37:17.850
And then AI comes and makes it possible again.

37:17.850 --> 37:18.780
But we never go back.

37:18.780 --> 37:20.460
I call it bring back the backlog.

37:20.460 --> 37:21.750
We never go back to the backlog

37:21.750 --> 37:22.710
and go, wait,

37:22.710 --> 37:24.330
what could I do now

37:24.330 --> 37:26.010
that I couldn't do before

37:26.010 --> 37:27.810
that might be worth revisiting?

37:27.810 --> 37:29.220
So I thought it would be a fun exercise

37:29.220 --> 37:31.740
to have each person talk about a use case

37:31.740 --> 37:33.660
that they'd love to see

37:33.660 --> 37:36.270
either done or revisited

37:36.270 --> 37:38.310
in the world of AI

37:38.310 --> 37:39.810
in the future of work.

37:39.810 --> 37:40.770
Maybe, Lindsey, we'll start with you

37:40.770 --> 37:42.360
and we'll just go down.

37:42.360 --> 37:43.830
<v ->There's a lot that comes to mind.</v>

37:43.830 --> 37:45.210
<v ->I know, but we have to pick one.</v>

37:45.210 --> 37:46.260
<v ->I remember trying to print out</v>

37:46.260 --> 37:48.006
the whole Internet one time.

37:48.006 --> 37:49.200
(Noelle and Lindsey chuckles)

37:49.200 --> 37:50.310
If I could just download

37:50.310 --> 37:51.870
that whole Internet into my brain,

37:51.870 --> 37:53.490
that would be amazing.

37:53.490 --> 37:55.470
But the one thing that I actually think about

37:55.470 --> 37:57.480
is not necessarily for myself,

37:57.480 --> 38:00.180
but for like the youth of today.

38:00.180 --> 38:02.340
And that's adaptability.

38:02.340 --> 38:06.450
And we're talking about having to retool and reskill

38:06.450 --> 38:08.340
and there are a lot of people as you mentioned,

38:08.340 --> 38:10.170
who are very reluctant to that.

38:10.170 --> 38:12.240
I think if we can start in schools

38:12.240 --> 38:14.610
and teach adaptability and realize

38:14.610 --> 38:16.320
that what you think

38:16.320 --> 38:17.160
you're going to do

38:17.160 --> 38:18.480
or what your dream is,

38:18.480 --> 38:20.550
is going to change.

38:20.550 --> 38:24.150
We're so fixated on you wanna be an X, Y, Z

38:24.150 --> 38:25.680
when you're five years old.

38:25.680 --> 38:28.110
And then like, we made this promise to ourselves

38:28.110 --> 38:29.460
that we're gonna do this

38:29.460 --> 38:31.350
and it's hard to break those promises.

38:31.350 --> 38:33.810
So I think if we can find a way to realize

38:33.810 --> 38:35.490
that we're gonna have to change

38:35.490 --> 38:36.810
and that we're gonna have to learn skills

38:36.810 --> 38:37.643
throughout our life,

38:37.643 --> 38:38.790
it's not just from school

38:38.790 --> 38:40.230
and then you're done.

38:40.230 --> 38:41.490
I think that would be something

38:41.490 --> 38:43.170
that I'd love to tackle.

38:43.170 --> 38:45.677
Not exactly sure how to make that happen.

38:45.677 --> 38:46.510
<v ->Yeah.</v>

38:46.510 --> 38:47.343
I mean a lot of soft skills that we're talking about.

38:47.343 --> 38:49.722
<v ->I think it can be taught.</v>

38:49.722 --> 38:50.700
<v ->Thank you.</v>

38:50.700 --> 38:51.533
<v ->Yeah.</v>

38:51.533 --> 38:54.660
Well, when I just look at the future

38:54.660 --> 38:58.560
for the typical small business software developer,

38:58.560 --> 39:01.920
I think it's actually a very bright future

39:01.920 --> 39:06.780
and already these tools are demonstrating themselves

39:06.780 --> 39:09.390
as vital augmentative means

39:09.390 --> 39:11.520
to make someone in some cases,

39:11.520 --> 39:16.170
exponentially more efficient and exponentially

39:16.170 --> 39:18.720
increase the quality of what they're working on.

39:18.720 --> 39:22.530
So there's a very, very little of a-

39:24.330 --> 39:25.740
I mean it's being fully embraced

39:25.740 --> 39:27.120
by the software development industry.

39:27.120 --> 39:27.953
I contrast that a little bit.

39:27.953 --> 39:31.140
Again, because I guess, I'm the lawyer here,

39:31.140 --> 39:33.483
but to look at the legal profession,

39:34.530 --> 39:35.760
that profession has existed

39:35.760 --> 39:37.150
for a very long time

39:39.630 --> 39:44.190
and the demographics undoubtedly skew older for lawyers

39:44.190 --> 39:46.440
than probably for developers.

39:46.440 --> 39:48.570
Uptake has really not been,

39:48.570 --> 39:50.310
I mean there's people get scared

39:50.310 --> 39:51.150
by the use case

39:51.150 --> 39:52.383
that we talked about.

39:53.400 --> 39:55.260
There'll probably be something of an evolution,

39:55.260 --> 39:56.490
a squeeze if you will,

39:56.490 --> 39:59.550
on some parts for a typical law firm

39:59.550 --> 40:04.260
in automating some administrative tasks.

40:04.260 --> 40:07.449
But I think that

40:07.449 --> 40:11.482
there's a very interesting contrast for me there.

40:11.482 --> 40:12.315
<v ->Great.</v>

40:12.315 --> 40:14.025
<v ->But even for the legal profession,</v>

40:14.025 --> 40:16.124
I think that the future is actually quite bright.

40:16.124 --> 40:19.020
And once people do get that training

40:19.020 --> 40:21.870
and I give full credit to bar associations

40:21.870 --> 40:22.703
and things like that

40:22.703 --> 40:24.540
who try to put those things together.

40:24.540 --> 40:26.670
<v ->Awesome.</v>
<v ->I think it will evolve well.</v>

40:26.670 --> 40:27.875
<v ->Wonderful.</v>

40:27.875 --> 40:28.708
Thank you.

40:28.708 --> 40:30.374
All right. And I hate to like grab,

40:30.374 --> 40:31.770
but like 30 seconds to,

40:31.770 --> 40:33.990
<v ->Sorry, I'm gonna do this quick. Yeah.</v>

40:33.990 --> 40:35.372
So coming from data,

40:35.372 --> 40:36.990
we spent a bunch of time,

40:36.990 --> 40:39.340
building these huge kind of data infrastructure

40:39.340 --> 40:41.400
at all kinds of companies.

40:41.400 --> 40:43.380
Pinterest, I think we built

40:43.380 --> 40:45.510
the first Pinterest data warehouse.

40:45.510 --> 40:48.150
We did it for Google for a little while.

40:48.150 --> 40:49.020
And you build these,

40:49.020 --> 40:50.640
you get all this data together

40:50.640 --> 40:52.020
and there are only a couple people

40:52.020 --> 40:53.610
that can use this system.

40:53.610 --> 40:55.140
And you have to ask those people

40:55.140 --> 40:56.730
when you have a question about the data.

40:56.730 --> 40:58.803
And I think up until five years ago,

41:00.216 --> 41:01.623
there was this promise

41:01.623 --> 41:02.970
that you could just use natural language

41:02.970 --> 41:04.350
to ask about your data.

41:04.350 --> 41:06.480
And everyone that's said that before,

41:06.480 --> 41:08.040
ChatGPT was lying to you.

41:08.040 --> 41:09.569
Like that's not possible.
<v ->Yeah.</v>

41:09.569 --> 41:10.402
<v ->Yeah.</v>

41:10.402 --> 41:11.880
And now finally, there's this ability,

41:11.880 --> 41:14.280
I think right around the corner or even like,

41:14.280 --> 41:15.510
I'm sure people are building it now,

41:15.510 --> 41:17.910
to really ask whatever you want,

41:17.910 --> 41:19.260
no matter where you are in the company

41:19.260 --> 41:20.190
or not in the company,

41:20.190 --> 41:23.310
if you have access to that data in regular language

41:23.310 --> 41:25.560
and get back an answer, which I think is gonna open up

41:25.560 --> 41:26.910
a whole world of possibilities

41:26.910 --> 41:29.760
for people being able to expand

41:29.760 --> 41:31.980
what they think of as their job

41:31.980 --> 41:34.950
and not feel kind of hemmed into corners.

41:34.950 --> 41:36.300
Now they can know much more

41:36.300 --> 41:37.650
about the work that they're doing,

41:37.650 --> 41:38.820
the impact of that work,

41:38.820 --> 41:40.470
the impact of other people's work

41:40.470 --> 41:42.270
and how it really fits into the whole,

41:42.270 --> 41:43.530
how they fit into the company.

41:43.530 --> 41:47.190
And I think that's really exciting for me personally,

41:47.190 --> 41:49.860
because I think it allows people to kind of dispense

41:49.860 --> 41:51.570
what the drudgery know more about things

41:51.570 --> 41:53.520
without having to go through kind of oracles

41:53.520 --> 41:56.550
and that's just an exciting future I think.

41:56.550 --> 41:57.390
<v ->Thank you, Bob.</v>

41:57.390 --> 41:58.559
All right.

41:58.559 --> 42:00.225
One quick one. Do you got a quick one?

42:00.225 --> 42:02.370
<v ->Lifelong career navigation.</v>

42:02.370 --> 42:04.757
If a healthcare system can say,

42:04.757 --> 42:05.880
in a year, you need this medical test,

42:05.880 --> 42:07.710
an AI system should be able to say,

42:07.710 --> 42:09.840
in six months, you need to develop this skill set

42:09.840 --> 42:11.100
to get the next job that you want.

42:11.100 --> 42:11.970
<v ->Oh, I love that.</v>

42:11.970 --> 42:13.305
Awesome.

42:13.305 --> 42:14.393
Okay, Adrian, ending with you.

42:16.172 --> 42:17.005
No pressure.

42:17.005 --> 42:17.838
<v ->I'm one of the special class of people</v>

42:17.838 --> 42:18.671
who went to school

42:18.671 --> 42:20.760
to learn how to be a coder.

42:20.760 --> 42:21.690
I should be fired.

42:21.690 --> 42:22.800
Everyone in this room

42:22.800 --> 42:24.750
can now build whatever they want.

42:24.750 --> 42:27.510
You don't need the special people anymore.

42:27.510 --> 42:30.450
Everyone is a builder, don't be afraid.

42:30.450 --> 42:31.470
<v ->Yes, everyone's a builder.</v>

42:31.470 --> 42:32.970
It's a great way to end.

42:32.970 --> 42:34.380
I wanna thank the panel.

42:34.380 --> 42:36.375
Thank you all for being here. I have a gift for you,

42:36.375 --> 42:37.710
so don't leave until I have a chance

42:37.710 --> 42:38.543
to give it to you.

42:38.543 --> 42:40.800
Someone in the audience in this general area

42:40.800 --> 42:42.420
has a tiger under their chair.

42:42.420 --> 42:44.100
You'll also get a free gift.

42:44.100 --> 42:46.410
So come see me afterwards.

42:46.410 --> 42:47.243
So excited.

42:47.243 --> 42:48.540
Thank you for being here with us.

42:48.540 --> 42:49.397
We're gonna stand up and take a selfie,

42:49.397 --> 42:51.900
'cause I take a selfie on every stage.

42:51.900 --> 42:53.730
If you don't wanna be on the Internet,

42:53.730 --> 42:54.960
I mean you're at CS,

42:54.960 --> 42:57.870
but if you don't wanna be on the Internet, just look away.

42:57.870 --> 42:59.107
But thank you, give a warm

42:59.107 --> 43:01.032
round of applause to our panel.

43:01.032 --> 43:03.655
(audience wooing and clapping)

43:03.655 --> 43:06.238
(upbeat music)

