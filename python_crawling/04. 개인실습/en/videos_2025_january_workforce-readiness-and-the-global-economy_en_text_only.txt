<v ->Awesome.</v>
So nice to be here with you all.
I think it's good.
We didn't level before, so they're leveling.
It's all good. I give them a couple seconds of me,
talking about random things.
I don't know
if you all remember these beautiful glasses.
I've worn them on
I think six CES stages
since they launched years ago,
the Meta frame.
So I always like to just tell people at home
what this actually looks like,
like being here and standing in front of you.
So thank you for taking time
out of your crazy schedule at CES
to join us today at the AI House.
I have an amazing panel of incredible people
from different parts of industry
as well as practice.
We've got a little policy professionals,
so it's going to be a very fun, wild ride
in the world of really,
what does the workforce look like
as AI starts to,
I don't know, take over everything.
So I wanna invite my panelists to come on up.
I'm gonna see
where I wanna put them seat-wise.
Come on, let's go.
I'm gonna invite-
Okay.
I'll say Lindsey will come up first
and Lindsey is one of the best storytellers.
Yes, give her a round of applause.
One of the best storytellers.
She's anchored many of news broadcasts.
She actually hosted me.
Come on down.
We'll have you sit right there.
Alex, I'm gonna have you sit
where my baby tiger is.
Amazing.
All right.
And then the gentleman can just pick a seat.
I hope that doesn't say
a lot about me right there.
Yeah, perfect.
Awesome.
All right. Then I'm gonna sit over here.
Cool. I was just gonna take whatever seat was available.
So obviously, we have a lot of people here today
to share with you some perspectives.
I wanna start first
by giving people an opportunity.
My eyeglasses are talking to me.
No, not right now.
The most important thing about the topic
that we're gonna share with you today
is that it impacts every single one of us
and that we all have different lived experiences
and my hope is that,
we'll be able to bring
some of those lived experiences to you
and how we've managed the world
of work and AI
throughout the last couple of years,
some of us much longer.
I'm Noelle Russell
and my journey into the world of AI
started actually at CES.
I was employee 10 on that product.
I built over a hundred apps for Alexa
in its first year,
owned 10% of the applications that were deployed,
got millions of users
and didn't know what the heck I was doing.
And realized that productizing AI
was very much that journey
of getting a good idea,
knowing how to clearly articulate it,
and then get it out into the world.
And so I've productized models at Microsoft,
at IBM, at Red Hat.
I'm a big practitioner,
but what I love most really,
is helping people who didn't really see an opportunity,
didn't see themselves in the world of AI,
start to see themselves that way.
So I have a community which actually,
I think a couple of us are in,
called the I Love-
I know, I have community members in the house.
The I love AI community.
It's a free community
where we just teach literally anyone
the art of AI.
And I do think that that is a core principle
of the workforce topics
we're gonna talk about.
So as we get started,
I wanna give everyone a chance to introduce yourself,
but then also talk a little bit
about how the workforce,
like the concept of the workforce
has changed for you
over the last two years.
And it's totally fine
if it hasn't changed at all,
though I don't think that will be the case.
But I would like to understand
a little bit about your background
and then give us a little idea about
what you think about the workforce right now.
So I'll start with you, Lindsey,
and we'll walk down the lane.
<v ->Sure.</v>
Thank you so much, Noelle.
Thank you for having me.
My name's Lindsey Mastis
and I'm an AI and tech news anchor.
I've been covering AI and tech
for about the past two years.
And up until Friday,
I was in TV broadcast news
and now I've gone independent
so that I can focus on
this pretty much full time.
So it's changed for me.
I've also seen the landscape
within the newsroom change a bit.
It's a little bit slower moving right now
because when it comes to journalists,
we wanna make sure everything's accurate.
So that's a little bit of a holdup.
But I also have reported
on AI and tech,
especially when it comes to the workforce
and a lot of parents that are concerned about
what should their children be learning
when it comes to
what they're gonna be doing in the future.
And then also talking to people
about having to pivot.
So, it's a really a broad spectrum right now,
but yeah, this is really impacting all areas
and it's an exciting time.
<v ->Absolutely.</v>
Thank you very much for that.
All right.
Let's keep going.
<v ->Hi.</v>
Thank you very much for having me.
Brian Scarpelli is my name.
I'm with a trade association based in Washington, DC
called ACT, The App Association.
It's a not-for-profit industry advocate
for the small business software developer
segment of the industry.
And I'm a lawyer for them.
So I thought actually,
I could touch on two kind of different angles.
One, the impact on the developer community,
I think, it's very much seen
as a vital augmentative tool
for code generation and finding bugs
and other quality checks and assurances,
for our community,
these are some micro companies
that have been developing
and using AI for years now.
And they're really leaning in, embracing it.
So there's a lot of positive.
I think quite positive from that perspective.
I mentioned that I'm a lawyer
just because I thought
it would be interesting
to talk about that
just for a moment.
Like how is that impacting the legal profession?
And AI tools are already
pretty critical in just document review, summarizing,
some kind of,
if you wanna call them pedestrian uses,
maybe transcription and things like that.
But there's some really interesting or infamous cases
that people might be aware of lawyers,
submitting briefs to courts
with hallucinated sites and cases,
and things like that,
and them getting into trouble.
<v ->Yeah.</v>
<v ->Yeah. These are themes that I think</v>
we'll probably touch on later.
I just thought I'd mention that too, but-
<v ->Yeah.</v>
Amazing.
Thank you. So we've got, like the scene is being set.
We've got a content creator, a storyteller,
a news professional media represented.
We've now got legal and policy represented.
So I think you'll find the diversity
of experience very, very interesting.
So Bob, I'd like you to go next,
if you don't mind.
<v ->Sure.</v>
Hi, my name is Bob Briski.
I work for a company called DEPT Agency.
We're half creative brand and media agency.
And then the other half is a technical data
and AI portion of the company.
And I work on the data and AI portion
and my team uses data
and a lot of the new generative AI capabilities
to build tools for the creative brand and media side.
And so, we have a couple AI accelerator tools
that help out our global workforce.
And it's been really interesting,
I think what we were talking about
over the last couple of years to see
how the actual use and experience
with these tools changes
the more creative part of our agencies,
view of those tools from fear-based,
I think at the beginning
to real embrace and feedback
and like hunger for more of these types of tools
to make their daily lives
just a little bit easier,
a little bit better
and a little bit more interesting.
And that's been really surprising
and nice to see,
'cause kind of fundamentally an optimist.
So it's nice to not be proven naive,
which a lot of times optimists are.
<v ->Amazing.</v>
Yes.
And so now we've got this perspective
from a technical perspective,
but also from an agency,
which I think is a,
I'm seeing lots and lots of agencies sprout up
in the last two years.
And so, I think
it's a really interesting perspective that you bring.
Alex and I go way back,
so I'm so glad
you were able to join us.
I don't wanna steal your own thunder,
so you go ahead and introduce yourself.
<v ->Thanks so much, Noelle.</v>
It's wonderful to be with all of you.
I'm Alex Swartsel.
I'm at a nonprofit called Jobs For The Future.
And our mission is to transform
education and workforce systems
in pursuit of equitable economic advancement for all.
What we mean by that,
is that the systems
that all of us probably have moved throughout,
whether in the United States
or around the world,
to connect to an education,
to training, and ultimately,
to a quality job and a career
that can sustain us and our families.
Well, too often those systems don't work
as well as they should and they don't talk to one another.
And so, our mission is to make sure
that everybody has access
to the kind of education and training
and to a quality job that will allow them
to support themselves and their families.
Our team focuses specifically on the role
that emerging technology can play in that work.
And we've been heading up
over just the last 18 months or so,
an intensive focus on AI
in the future of work.
And so, I think what we've seen
with a lot of help from Noelle
and others on the team, right.
What we've seen,
I think is in the short-term,
a really intensive focus
on AI competency and skill development.
So just as all of you should have raised your hands
when we asked about
who is developing AI skills?
That's gonna be critical
for every single job across the workforce
because these tools and platforms will be everywhere.
But we're also, I think,
starting to see shifts
in some of the bigger questions
that we're asking about the future of work.
I think in this sort of complex landscape
that we're operating it within,
both from the last panel
where there are some real questions being asked
about potential labor savings
through productivity growth and so forth,
and risks to jobs in that dimension,
but also the opportunities
that others of the panel have spoken about
for more fulfilling and creative roles,
even for job creation in different ways.
And so I think for us,
it boils down to a couple of key questions
that I hope will be part,
not just of this conversation,
but of the whole conversation
around AI long into the future.
And one of those is,
what is the work
that we as a society believe
that only humans can or should do,
whether it's in partnership with AI or alone.
And then secondly,
how can we make sure
that progress in AI
works to ensure that everybody has access
to a livelihood and a quality job?
And that's a standard
by which we need to evaluate AI
and we're not talking enough about that.
So I hope we can get into this, some of that more today.
<v ->Oh my gosh, great.</v>
I love it.
Yes.
Yes, I love that topic.
I hope, I know we're gonna
at least get an opportunity
to talk about it
at the end this week.
Close it out.
So thank you for that.
And Adrian, I think compliments all of us very nicely
because he provides a slightly larger scale
view of the world.
So I'd love the audience to understand
a little bit about what you do
and your view of the workforce.
<v ->Hi, everyone, great to be here.</v>
I'm Adrian McDermott.
I'm the CTO of a software company called Zendesk.
We make customer service software
for about a hundred thousand businesses.
There's four to 5 million people
using our platform every day
to give customer service
to our customer's customers.
I think from an AI point of view,
I really feel like
I'm straddling three different worlds.
One is the builders of software and the technologists.
And I think they are adapting
to this paradigm shift.
And it's an interesting paradigm shift for developers
because for a developer expects
to ask an API
the same question with the same data
and get the same answer.
Unfortunately, LLMs don't behave that way.
Or fortunately.
They're a little more creative than that.
They're unreliable like us,
like me, which is great.
And so training people to adapt to that,
but also then to trust the tools
and use the tools,
is part of what we're doing
and then to build on top of it.
Secondly, in customer service,
it is generally agreed.
I think that customer service is gonna be one
of the first places
where jobs will change.
The nature of work will be different.
Customer service generally scaled
using human power, right.
All of the metrics
of customer service time
to first response, average handle time,
they're all about managing human capital
and human capital time.
The marginal cost of the next AI agent is obviously zero.
And so there are different metrics
and different things that happen and we can,
I think talk about,
it's a core,
I think case and things that are,
it's happening today
where people have been re-skilled
and we're using copilot technologies
and the nature of work is changing.
And then thirdly, actually in my extracurricular life,
I'm on the board of a company
called Be My Eyes,
which is an app
for the blind and partially cited,
what I just wanted to mention that
as it's embedded in your Meta glasses.
<v ->Yes.</v>
<v ->So were you someone without vision</v>
or who needed vision assistance,
you could call for Be My AI to help you,
or for one of the 7 million volunteers
on the platform to come in
and tell you what you are looking at,
how to get a taxi.
Is that taxi free?
These kind of things.
And I think that is a great example
of the way that this technology can really change
the way people live and the accessibility
and the way that they can get around
and experience the world.
And we have to think differently about the apps
that we can build upon it.
<v ->Oh my gosh, I love that.</v>
And I'm a big believer in accessibility.
I feel like it's the tip of the spear
and pushes a lot of really great technology into the world.
So thank you for sharing that.
And yes, I do actually use it often.
I do use it to tell me
when there's a Starbucks nearby,
but still, it's fine.
But I also have a child with Down Syndrome
and so he uses it
in a much more practical way
and it inspires me.
It inspires me that it takes a team
like the one you're talking about,
to actually say, yes,
I'm willing to solve that problem
and I'm willing to build that technology
and then willing to put it into production.
In order to do that though,
the people that do this work
do need to get skilled.
And so you mentioned re-skilling.
I don't have time to ask everybody every question,
so I handpicked the people
that I'm gonna ask this question of.
But Lindsey and Bob,
I'm gonna go to you about re-skilling.
It's a hot topic.
Everyone's talking about re-skilling.
It's in the new,
the EU ACT is presenting a regulation around reskilling,
which I'm happy for,
because I'm an educator, so yay me.
So it's gonna be a good time.
But I would be very curious, not necessarily broadly,
but very specifically, I mean,
especially as a personality,
as someone who is a trusted advisor to communities
through the news work that you do.
And Bob, in your role at the agency,
I would like to understand
what you personally do
to stay skilled up, right.
What advice can we give?
Like how are you just keeping up with the systems
and tools and ideas
that are coming out,
coming fast and furious over the last?
So I'll start with Lindsey
and then Bob, go to you.
<v ->Sure.</v>
So for me, I had to make a point
that every day, part of my day,
I'm carving out to stay up-to-date.
Now part of that is because I need to know
what's going on in the world of AI,
the news world of AI.
But part of it,
it's also that I need to know
not only what I'm talking about,
but also what skill
do I need to learn
so that I'm prepared for that next step.
And I mean, I have vision and some ideas
of what the future's going to look like.
And I really do believe
that we're going to have AI anchors in the future.
And I'm not exactly sure
if it's gonna be just an avatar
or if it will be me as an AI.
And I need to know how to use these tools
to like deep fake myself basically,
so that I can own myself.
<v ->Yes.</v>
<v ->But also think about it,</v>
if I get sick, no one wants to hear a sick anchor.
If I'm coughing or my voice is kind of scratchy
and you're trying to listen to the news in the morning,
it's distracting.
It's distracting to me
to try to read the news that way.
It'd be great for my AI
to just take over that day.
That would be wonderful.
Or also, what if you really love
getting your news from me,
you trust me and my AI can go
all day and all night,
it won't sleep.
But then I'm still human,
so I can still maybe meet
with people in real life.
I can still do
some of the in-person work,
but the sitting at the anchor desk and speaking,
that might become AI.
So I'm actually looking at what skillset
I need to develop
and maybe some of these tools
are in their infancy right now,
but at the very least,
I need to know about them.
So it doesn't mean
that I have to know
how to put the whole car together.
I just need to know that this thing's driving
and then I make a decision about what skill I need.
But I talk to so many people
who are trying to re-skill right now
and trying to pick which part of AI.
It's hard, especially for someone like me
who's interested in all of it.
So, that's partly of,
I'll make some decisions about
what specifically I'm going to learn.
I've taken your bot class
in the past as well,
so I've programmed a bot, which was awesome.
A chat bot I should say.
I would love to program an actual bot,
but I can't do it all.
I have to make some choices.
<v ->Yeah. And I think daily practice is so important,</v>
like making it a daily habit.
I always tell people,
I talk to lots of executives.
People that might be characterized
as part of a silver tsunami that's happening.
Have you heard this term where lots of people
with silver hair are leaving the workforce.
And they're like,
I don't need to know anything about this.
And I'm like, well, it'd be great if you did.
And then I teach them,
I re-skill them not through,
hey, do take this class, listen to this lecture.
I literally do what we do in our bot class
where we bring people in
and we actually have them build a system
for someone they care about,
someone in their ecosystem.
And it is in that awareness
that they get very excited.
I'd love for Bob for you
to talk a little bit about
what you do every day
or what you're thinking about in terms of re-skilling
for those who are in a similar role.
<v ->Yeah.</v>
So for anyone trying to keep up
with all the technology
and changes that are happening, just stop.
'Cause my wife works in AI,
I work in AI,
I talk about AI all day.
My team talks to me about AI.
People ask me questions about it all day,
and I haven't even scratched the surface.
It's just impossible right now.
It's moving way too quickly.
I think what we try to do
is take what we know
about the work that we're doing,
about what we're building,
about our business strategy
and apply the technology
as well as we can
to reach the goals that we have
that we had set for ourselves before.
I think, I had talked to somebody about this before,
just using the technology is like getting
in a fast car and driving nowhere.
Like you're not gonna get anywhere,
you're not gonna know where you are
when you get there.
You want a direction that you want to go.
And so concentrating on that is I think the best way
to really get your hands around
a lot of this new technology.
As far as re-skilling,
like from a personal level,
I don't think of it
as re-skilling as much as expanding
my knowledge into areas
that I didn't think I had time
to really get into before.
So I work at a creative agency,
but we were acquired,
we were a data and engineering agency before,
so I haven't worked with creatives
and that was just an interesting change.
A lot of engineers working with creatives.
There's sometimes some friction there.
But now I can really use
some of these tools,
ChatGPT, being one of them,
but also the tools that they're asking me about
to get an idea
of what their workflow is,
how they think about the work that they're doing.
And so when I talk to them,
I have a much more universal idea
of how they think about their work.
And so we can start to talk on the same level
that we weren't able to talk about before.
And just me, staying humble about
what I don't know and realizing that the way
that I speak to people
before was really like,
just thinking that you need to speak
the most about the stuff
that you know the most about,
is probably not the best way to communicate.
And now I can start talking the way
that they're used to talking about,
or maybe they're thinking
about their work in a way
that I just wasn't able to before.
<v ->Yeah. I love that closing the gap.</v>
Like in these conversations,
many of us have been in that situation
where we come from our perspective
and then we talk to someone and you're like,
why don't you understand what I'm saying?
So it's really great to have a tool
that can articulate that
and especially in something
like a Microsoft copilot
where it can actually help you craft emails
contextually for the team
that you're talking to.
It's really exciting stuff. So thank you for that, Bob.
That's amazing.
So I'm gonna shift to another question
and I'm actually gonna focus,
I didn't realize I put you both together,
but you're both gonna be answering this question,
so I'll give you a chance to think about it.
But this question is more about
kind of the future job market
and what you're thinking about in that area.
Like how are you preparing yourself,
but also your teams
and for you, Alex,
maybe like, the work that you're doing,
I think it'd be nice to see
a little bit behind the curtain
in some of the conversations
you're having about like,
how does this actually work
inside of a large business
where you're thinking about lots of people,
what is your-
I don't know either projections or current plans
for how are you going to tackle
this need to skill everyone up?
<v ->I'm happy to start with that</v>
and to talk both about
how we're thinking about it
within jobs for the future,
but also how we're engaging
with our partners across the ecosystem
who are not just major employers and technology companies,
but colleges, universities, community-based organizations
and others who are really wrestling with this.
So for ourselves,
I think we're trying to both ask the questions
about where we can start
to leverage these tools today using piloting approaches
as many of you all
have done as well,
but with a really intense focus on living into our values
as a nonprofit that is focused on this space
and the future of work.
And on this question
of how we're building foundational AI
competency skills amongst our teams.
So I'll give you just one example. We have a pilot starting
just in a couple of weeks
and as we're not only taking applications
from across the entire organization,
every level, every department,
so that this rollout is not siloed in any way,
but we are also making it a requirement
that people engage in AI competency training
before they can start.
Because we know that
and at least are starting
to hear some inklings
that you don't have to worry
about deeply understanding AI.
You just need to understand
how to use this one tool
and you'll be fine.
But because we know this technology
is moving so quickly
and so much of the way
in which you can use it effectively,
depends on a deeper understanding
of what it's good at, what it's not,
what its limitations are today,
what its capabilities might be tomorrow
that we believe strongly that everybody needs
to have that foundational level of understanding.
And then in terms
of how we're talking about it to the field,
a lot of it does center
on how we believe jobs may change
and the skills that are going to be in demand,
especially where we need to support
that kind of skill development for populations
that may have experienced barriers
to economic advancement in the past.
Whether that's because people have criminal records
or people don't have bachelor's degrees, for example.
And so, I mentioned before
and everyone is experiencing it,
that there is an intensive near term focus on AI competency,
which is great for all the reasons
that we've just talked about.
But we're talking a lot
to the field about a deeper layer
of changes in demand skills.
We believe that human skills,
what we used to call soft skills,
being able to collaborate,
to communicate effectively with a wide variety of audiences,
to be able to engage cross-functionally amongst teams,
to use critical thinking skills,
so that you can evaluate the outputs
of AI tools effectively and know
if an output is the right one
for the decision you're trying to make,
those skills are going to be essential.
But we also see others as well,
whether that's entrepreneurship.
Somebody said earlier today,
all engineers need to be entrepreneurs.
We think every worker needs
to have entrepreneurship skills
because that will allow people to spot opportunities
to not just have productivity gains
that in the long run,
could potentially eliminate jobs or risk jobs.
But for the creation of new business value of new products
and services, new businesses and ideas,
we're already starting anecdotally
to see entrepreneurs, small business owners using AI tools
to dramatically uplevel their business,
to be able to grow in ways that they couldn't
because of capital constraints or other factors.
And that's really exciting
because that ultimately redown to job creation.
So what we're trying to do within our ecosystem
is just to push the boundaries
of the conversation a little bit to say,
here's some things
that you might not be thinking about today,
but that you should,
whether that's skill development,
whether it's other opportunities to use AI
to generate economic opportunity and mobility
because it's moving so fast
that if we don't act in those ways today,
if we don't put those pieces in place,
we're gonna get left behind.
<v ->Awesome, I love it.</v>
Thank you very much.
Adrian, what are your thoughts on it?
<v ->Well, I think about the way</v>
that we speak specifically to our customers
and they're probably driving
some mission around customer service
and a core principle that we remind them of,
is that no one ever says,
oh, you know what,
I have enough customer service.
I don't really need anymore, right.
And so, the opportunity here,
I think it's easy to swing
towards cost saving and reduction of force.
A lot of people are stepping away
from seasonal hiring for Black Friday
and these kind of things,
'cause they working towards automation.
But our focus with our customers
is really directing them
towards the experiences that they want to build.
What are the customer journeys
and the experiences you want your customers to have?
How do you think your brand can differentiate
when everyone can have really
high quality service available 24/7,
because it's automated and zero marginal cost.
Like what are you gonna do to differentiate?
And since the introduction
of the telephone brought with it,
the removal of face-to-face service,
but it enabled us to have scripts and queues
and all these rituals
of customer support that came in
and people didn't necessarily like them, right.
We hit zero
because we want the human touch
or because we're in a moment of panic or stress
or we need empathy
or we don't have enough trust
in the right answer.
And I think guiding people towards seeing
how AI is a tool,
it's a tool that can help further your advancement
towards your ultimate goals.
It's a tool that can help you grow
your business by connecting better,
have providing better service, cross-selling, upselling,
doing all the things that you want to do,
and really re-skilling
and deploying the human population
where they're best.
People are not at their best explaining to other people
how to change their password.
People are at their best connecting with humans
in these human interactive tasks
that require judgment and socialization.
And I think as long as we remember that
as we design these systems of interaction
and however it is we're deploying AI,
remember what we're good at,
that is to a certain extent,
I'm gonna say right now, irreplaceable anyway.
I think as long as we remember that
we can help drive our businesses,
our organizations towards a mission
and make sure that we're keeping the human touch.
<v ->Absolutely.</v>
And I've worked a lot
in the context center space
and I think it's very interesting
because it's one of those areas
that's got high volatility
in maintaining people in the role
for a lot of reasons
that you had mentioned
and that one of the most financially impactful strategies
organizations implemented over the last year.
As a matter of fact,
we did a article in Harvard Business Review,
happy to share it with you all,
but it talked about like
the number one thing was helping the helper,
was leveraging your new found knowledge
and skills in AI to actually build systems
that help the people
that are talking to the humans.
That you're right.
When my dad lives with me,
my dad, he never wants,
I mean, he talks to Alexa every day,
but not about anything he cares about.
When it comes to something he cares about,
he wants to talk to a human
and he's the first one to eject himself
out of the IVR system
we've painfully created over the last 20 years.
So we're moving into a part
of the session that I like.
It's a little black mirrory,
but I like it,
because we'll end somewhere hopefully nice.
But I'd like to start by sharing with you,
some of you saw me bring a stuffed tiger.
It is an emotional support tiger, yes.
But I bring it on stage as a reminder
because as companies start investing in this technology,
his name's Bruiser.
I know someone just asked that in their mind.
So yeah, it's Bruiser.
And one of the things
that often happens is that people adopt AI
like they are adopting a baby tiger.
Like they get a baby tiger and they're like, oh my gosh,
it's so cute and adorable,
and I love it. And it can do this thing
and I wanna take a picture
and can I join that team? That'd be fun.
It's very, very enthusiastic, hype.
It's why there's a cycle around it,
the hype cycle, right.
But over time, as that tiger begins to grow,
it is 100% dependent on you,
on the workers to actually train that tiger
to become a confident, safe, secure way
to help amplify the work that people do every day.
And so, it becomes a reminder to me,
I have people give me baby tigers,
I carry one around with me all the time
to remind me that every time
we start an AI journey,
it starts off with something
that seems pretty cool,
but could just as easily hurt us.
And so I share that
because I'd like a couple of people,
I mean, if you wanna jump in
some others who don't get picked,
it's a good topic,
but I wanna just have a couple people share
some of the biggest blunders they've seen.
As a matter of fact,
Brian, we talked about it.
So I think one of those blunders would be great.
And then I'm also going to have, Adrian,
I know you got some good scary stories in customer service,
so I just thought it'd be good for you
to see kind of the worst of it.
Like how does this not go well?
So maybe Brian, you can get started with that.
<v ->Sure.</v>
From a couple different angles
I can think about.
I mean, just from like the software development angle,
there's driven by the need to compete
and hype and things like that.
Some products will get rolled out
without fully developing guardrails
that might be needed.
And the most extreme
or maybe famous examples of that
might be things like facial recognition
that depending on the color of someone's skin,
might not recognize 'em or confuse them,
and things like that
that everyone can really connect with.
To me, from the software development angle,
that's probably one thing
that I think of.
The example I know
that that not to be mysterious
that we had been talking about
was the hallucinated cases citations.
And just for anyone who's not familiar
with the story, with these circumstances is,
there was a lawyer
who was suing an airline in New York
and he used ChatGPT
to write his legal brief
and then he filed it with a court
and it contained made up cases
and he was actually given an opportunity
to correct the brief and didn't.
So he ended up getting sanctioned
and suspended from practicing
for like five years
and they put out a press release about,
they wanted to make an example.
So, learning-
<v ->Fire.</v>
<v ->Yeah.</v>
Learning by fire there.
But I guess, those are kind of two examples.
One other one that I could maybe throw in there
just because spend a lot of time
with my trade association doing policy advocacy,
mostly with the federal government is,
I think from that perspective,
from the people setting these rules,
there has been definitely
over the last year
and a half two years,
a real rush to jump in and regulate
and the example that I can give there is,
there was a non-discrimination rule
under the Affordable Care Act
that was put into place
by the Health and Human Services department,
which put strict liability on any doctor
who uses AI defined super broadly.
Like even using the sum function
in an Excel spreadsheet potentially,
could meet this definition.
So if they use this AI
then they face strict liability.
And I think there's a negative impact on the work.
It's a great reason to say no,
when you talk to your internal counsel
or something like that for a lawyer to say,
no, the risk is too high,
just don't use it
and not pick up the tools at all.
So we're always trying to encourage
regulations being put into place
to be technology neutral
and based on reasonably expected
or demonstrated harms rather than hypotheticals.
But three different angles
I thought I threw out there.
<v ->Yeah, I love it.</v>
I love it. I mean, so I have baby tiger moments on LinkedIn.
I post baby tiger moments
of all of these.
There are hundreds of very reputable companies
going into production with nonsense
that hurts their companies, their clients.
And what I say is like,
yeah, it's sad to watch,
but it's extremely valuable
for you all as like people
who will do this work,
we can learn from them.
At least, we could learn from them.
Adrian, any good stories come to mind
that you'd like to share with us
that wouldn't hurt you too hard to tell.
<v ->Well, firstly, I should acknowledge</v>
that my name is Adrian
and I have deployed some **** bots.
and I apologize, I'm deservedly.
<v ->Hi, Adrian.</v>
<v ->But in all seriousness,</v>
I think people get excited about the cost saving aspect
or about some other efficiency aspect of technology
and then they create bad experiences
and they generally get found out.
That's category one
of what can go wrong, I think.
And it's the one,
a lot of us are familiar with, right.
Our first AI model we released in 2014,
it was trained on a hundred thousand tickets.
GPT-4 is trained on the entire internet.
Big difference.
<v ->Yeah.</v>
<v ->It understands a lot more</v>
of what people are saying to it,
much better experience, right.
And so understanding the limits of your technology
and what you can do to deploy it, really important.
That's category one disaster.
Category two, I think would be politely formulated
as mess around and find out, right.
You are like an extreme risk taker company
and you're like, ah,
this is really cool.
I'm having a little nerdgasm over the way,
it answers my questions.
Let's just put it live and see how it goes.
There was another airline example actually,
an airline that did that and GPT-4,
if you ask it a question,
it is sort of trying to generate the next token,
which gives you the most viable answer.
So if you ask it,
what is your bereavement policy?
It's like, well, you're a national airline,
you probably have a bereavement policy.
If someone is bereaved,
they can book and change a ticket with no fees.
And so it told the user something plausible,
it gives the most plausible answer, not correct.
And ended, I believe in a class action lawsuit,
if I'm not mistaken.
<v ->Yes.</v>
<v ->And so, I think you kind of dance</v>
between those two sides of the equation.
You wanna be forward thinking,
you wanna deploy technology,
you also don't want to give people terrible experiences
and gate the thing too much
and kind of do that.
And I think the happy path in the middle
is one that is becoming much clearer
and thankfully, the technology gets better
basically every month
and it's becoming much easier to achieve.
<v ->Yeah, amazing.</v>
I love it.
I mean it's terrifying
but exciting all at the same time.
So as we close out the panel,
I always like to end
with hopefully, some practical ideas about
how we see the future of the workforce.
I know personally, I work with lots of clients.
We have an AI accelerator,
we take 'em in 90 days.
We go from in enthusiasm to execution,
which is my new book,
enthusiasm to execution,
which means we start with an idea,
then we build a model
and then we deploy it in 90 days.
The way we do that successfully
is through a concept known as red teaming.
And it literally is doing what we did up here,
bringing together a bunch
of very different perspectives
and having them actually work with a model
to ensure that you don't deploy it prematurely.
And if you do deploy it,
you deploy it to people
that'll give you good feedback.
These are very important, I think processes,
but what I'd like to do
is have every person on the panel
kind of think about a use case
in that maybe they've thought about,
I don't know, 10 years ago
and because of technology, because of resources,
they couldn't get it done.
Like so many times,
we have a dream
like I'm gonna translate
every piece of content I've ever written.
Oh wait, that's hard, nevermind.
And we forget about doing it.
And then AI comes and makes it possible again.
But we never go back.
I call it bring back the backlog.
We never go back to the backlog
and go, wait,
what could I do now
that I couldn't do before
that might be worth revisiting?
So I thought it would be a fun exercise
to have each person talk about a use case
that they'd love to see
either done or revisited
in the world of AI
in the future of work.
Maybe, Lindsey, we'll start with you
and we'll just go down.
<v ->There's a lot that comes to mind.</v>
<v ->I know, but we have to pick one.</v>
<v ->I remember trying to print out</v>
the whole Internet one time.
If I could just download
that whole Internet into my brain,
that would be amazing.
But the one thing that I actually think about
is not necessarily for myself,
but for like the youth of today.
And that's adaptability.
And we're talking about having to retool and reskill
and there are a lot of people as you mentioned,
who are very reluctant to that.
I think if we can start in schools
and teach adaptability and realize
that what you think
you're going to do
or what your dream is,
is going to change.
We're so fixated on you wanna be an X, Y, Z
when you're five years old.
And then like, we made this promise to ourselves
that we're gonna do this
and it's hard to break those promises.
So I think if we can find a way to realize
that we're gonna have to change
and that we're gonna have to learn skills
throughout our life,
it's not just from school
and then you're done.
I think that would be something
that I'd love to tackle.
Not exactly sure how to make that happen.
<v ->Yeah.</v>
I mean a lot of soft skills that we're talking about.
<v ->I think it can be taught.</v>
<v ->Thank you.</v>
<v ->Yeah.</v>
Well, when I just look at the future
for the typical small business software developer,
I think it's actually a very bright future
and already these tools are demonstrating themselves
as vital augmentative means
to make someone in some cases,
exponentially more efficient and exponentially
increase the quality of what they're working on.
So there's a very, very little of a-
I mean it's being fully embraced
by the software development industry.
I contrast that a little bit.
Again, because I guess, I'm the lawyer here,
but to look at the legal profession,
that profession has existed
for a very long time
and the demographics undoubtedly skew older for lawyers
than probably for developers.
Uptake has really not been,
I mean there's people get scared
by the use case
that we talked about.
There'll probably be something of an evolution,
a squeeze if you will,
on some parts for a typical law firm
in automating some administrative tasks.
But I think that
there's a very interesting contrast for me there.
<v ->Great.</v>
<v ->But even for the legal profession,</v>
I think that the future is actually quite bright.
And once people do get that training
and I give full credit to bar associations
and things like that
who try to put those things together.
<v ->Awesome.</v>
<v ->I think it will evolve well.</v>
<v ->Wonderful.</v>
Thank you.
All right. And I hate to like grab,
but like 30 seconds to,
<v ->Sorry, I'm gonna do this quick. Yeah.</v>
So coming from data,
we spent a bunch of time,
building these huge kind of data infrastructure
at all kinds of companies.
Pinterest, I think we built
the first Pinterest data warehouse.
We did it for Google for a little while.
And you build these,
you get all this data together
and there are only a couple people
that can use this system.
And you have to ask those people
when you have a question about the data.
And I think up until five years ago,
there was this promise
that you could just use natural language
to ask about your data.
And everyone that's said that before,
ChatGPT was lying to you.
Like that's not possible.
<v ->Yeah.</v>
<v ->Yeah.</v>
And now finally, there's this ability,
I think right around the corner or even like,
I'm sure people are building it now,
to really ask whatever you want,
no matter where you are in the company
or not in the company,
if you have access to that data in regular language
and get back an answer, which I think is gonna open up
a whole world of possibilities
for people being able to expand
what they think of as their job
and not feel kind of hemmed into corners.
Now they can know much more
about the work that they're doing,
the impact of that work,
the impact of other people's work
and how it really fits into the whole,
how they fit into the company.
And I think that's really exciting for me personally,
because I think it allows people to kind of dispense
what the drudgery know more about things
without having to go through kind of oracles
and that's just an exciting future I think.
<v ->Thank you, Bob.</v>
All right.
One quick one. Do you got a quick one?
<v ->Lifelong career navigation.</v>
If a healthcare system can say,
in a year, you need this medical test,
an AI system should be able to say,
in six months, you need to develop this skill set
to get the next job that you want.
<v ->Oh, I love that.</v>
Awesome.
Okay, Adrian, ending with you.
No pressure.
<v ->I'm one of the special class of people</v>
who went to school
to learn how to be a coder.
I should be fired.
Everyone in this room
can now build whatever they want.
You don't need the special people anymore.
Everyone is a builder, don't be afraid.
<v ->Yes, everyone's a builder.</v>
It's a great way to end.
I wanna thank the panel.
Thank you all for being here. I have a gift for you,
so don't leave until I have a chance
to give it to you.
Someone in the audience in this general area
has a tiger under their chair.
You'll also get a free gift.
So come see me afterwards.
So excited.
Thank you for being here with us.
We're gonna stand up and take a selfie,
'cause I take a selfie on every stage.
If you don't wanna be on the Internet,
I mean you're at CS,
but if you don't wanna be on the Internet, just look away.
But thank you, give a warm
round of applause to our panel.